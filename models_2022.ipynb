{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS THE MAIN FILE USED TO CREATE ALL MODELS\n",
    "# We have so far implemented two models: Logistic Regression and SVM.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "## TRAINED MODELS FOR PREDICTING THE 2022 PLAYOFFS ##\n",
    "#####################################################\n",
    "\n",
    "\n",
    "#####################################################\n",
    "## PREDICTING THE 2022 EASTERN CONFERENCE PLAYOFFS ##\n",
    "######################################################\n",
    "\n",
    "\n",
    "##############################################################\n",
    "## READING IN TRAINING DATA THAT HAS BEEN PREVIOSLY CLEANED ##\n",
    "##############################################################\n",
    "\n",
    "# Creating two empty lists that are used to store the data that is read in.\n",
    "x_train_list = []\n",
    "y_train_list = []\n",
    "# Iterating through the data for all the years.\n",
    "for i in range(2000, 2021):\n",
    "    # We ignore the year of 2004, as there seems to me something wrong with the formatting of the data in out dataset.\n",
    "    if i != 2004:\n",
    "        # Assembling in the name of the file that contains the x data that needs to be trained.\n",
    "        file_name = \"season_stats/east\" + str(i) + \".csv\"\n",
    "        # Reading the x data from the filename created above.\n",
    "        df_x = pd.read_csv(file_name, index_col=0)\n",
    "        # Sorting the data according to the values in the TEAM column.\n",
    "        df_x = df_x.sort_values(\"TEAM\")\n",
    "        # Resetting the index of the data.\n",
    "        df_x = df_x.reset_index()\n",
    "        # Dropping the TEAM column in the data.\n",
    "        df_x = df_x.drop(\"TEAM\", axis=1)\n",
    "        # Dropping the extra index column in the data.\n",
    "        df_x = df_x.drop(\"index\", axis=1)\n",
    "        # Appending the current round of data to the overall list holding all the x data.\n",
    "        x_train_list.append(df_x)\n",
    "        # Assembling in the name of the file that contains the y data that needs to be trained.\n",
    "        file_name = \"playoff_labels/east\" + str(i) + \"playoff.csv\"\n",
    "        # Reading the y data from the filename created above.\n",
    "        df_y = pd.read_csv(file_name, index_col=0)\n",
    "        # Sorting the data according to the values in the TEAM column.\n",
    "        df_y = df_y.sort_values(\"TEAM\")\n",
    "        # Resetting the index of the data.\n",
    "        df_y = df_y.reset_index()\n",
    "        # Dropping the TEAM column in the data.\n",
    "        df_y = df_y.drop(\"TEAM\", axis=1)\n",
    "        # Dropping the extra index column in the data.\n",
    "        df_y = df_y.drop(\"index\", axis=1)\n",
    "        # Appending the current round of data to the overall list holding all the y data.\n",
    "        y_train_list.append(df_y)\n",
    "\n",
    "# Concatentating the list of x data to a dataframe to hold all the x data.\n",
    "x_train = pd.concat(x_train_list)\n",
    "x_train = x_train.drop(\"MATCHUP\", axis=1)\n",
    "x_train = x_train.drop(\"WLPCT\", axis=1)\n",
    "# Concatentating the list of y data to a dataframe to hold all the y data.\n",
    "y_train = pd.concat(y_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "## READING IN THE TEST DATA ##\n",
    "##############################\n",
    "\n",
    "# Assembling in the name of the file that contains the x data that needs to be tested against.\n",
    "x_test = pd.read_csv(\"season_stats/east2022.csv\", index_col=0)\n",
    "# Sorting the data according to the values in the TEAM column.\n",
    "x_test = x_test.sort_values(\"TEAM\")\n",
    "# Resetting the index of the data.\n",
    "x_test = x_test.reset_index()\n",
    "# Dropping the extra index column in the data.\n",
    "x_test = x_test.drop(\"index\", axis=1)\n",
    "x_test = x_test.drop(\"MATCHUP\", axis=1)\n",
    "x_test = x_test.drop(\"WLPCT\", axis=1)\n",
    "# Assigning the test data to a variable that tells us that this is the prediction that should be made.\n",
    "x_test_prediction = x_test\n",
    "# Dropping the TEAM column in the data.\n",
    "x_test = x_test.drop(\"TEAM\", axis=1)\n",
    "# Assembling in the name of the file that contains the y data that needs to be tested against.\n",
    "y_test = pd.read_csv(\"playoff_labels/east2022playoff.csv\", index_col=0)\n",
    "# Sorting the data according to the values in the TEAM column.\n",
    "y_test = y_test.sort_values(\"TEAM\")\n",
    "# Resetting the index of the data.\n",
    "y_test = y_test.reset_index()\n",
    "# Dropping the extra index column in the data.\n",
    "y_test = y_test.drop(\"index\", axis=1)\n",
    "# Assigning the test data to a variable that tells us that this is the prediction that should be made.\n",
    "y_test_prediction = y_test\n",
    "# Dropping the TEAM column in the data.\n",
    "y_test = y_test.drop(\"TEAM\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "## STANDARDIZING THE X DATA ##\n",
    "##############################\n",
    "# Creating a scaler object.\n",
    "sc = StandardScaler()\n",
    "# Scaling the x training data.\n",
    "x_train_scaled = sc.fit_transform(x_train)\n",
    "# Scaling the x test data.\n",
    "x_test_scaled = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "## NORMALIZING THE X DATA ##\n",
    "############################\n",
    "# Normalizing the x scaled training data.\n",
    "a = preprocessing.normalize(x_train_scaled, axis = 0)\n",
    "# Creating a new dataframe to hold the saled, normalized x training data.\n",
    "x_train_normalized = pd.DataFrame(a, columns = x_train.columns)\n",
    "# Normalizing the x scaled testing data.\n",
    "b = preprocessing.normalize(x_test_scaled, axis = 0)\n",
    "# Creating a new dataframe to hold the saled, normalized x testing data.\n",
    "x_test_normalized = pd. DataFrame (b, columns = x_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION MODEL FOR THE 2022 NBA SEASON IN THE EASTERN CONFERENCE\n",
      "\n",
      "Score for training data: 0.8066666666666666\n",
      "Score for testing data: 0.6666666666666666\n",
      "\n",
      "Most important features for 2022 in the Eastern Conference\n",
      "('PM', 4.192892339967322, 4.192892339967322)\n",
      "('FGPCT', 1.5612884719530524, 1.5612884719530524)\n",
      "('FG3PCT', 1.2539959951474446, 1.2539959951474446)\n",
      "('TOV', -1.2041265228950269, 1.2041265228950269)\n",
      "('STL', 1.1156588648834882, 1.1156588648834882)\n",
      "\n",
      "Predictions for which teams makes the playoffs for 2022 in the Eastern Conference\n",
      "   TEAM  PLAYOFF  PREDICTION  PROBABILITY\n",
      "4   CHI        1           1     0.964768\n",
      "12  PHI        1           1     0.958279\n",
      "1   BKN        1           1     0.956483\n",
      "9   MIL        1           1     0.946853\n",
      "5   CLE        0           1     0.933985\n",
      "3   CHA        0           1     0.923703\n",
      "8   MIA        1           1     0.903250\n",
      "2   BOS        1           1     0.845746\n",
      "0   ATL        1           1     0.829961\n",
      "7   IND        0           1     0.713274\n",
      "14  WAS        0           1     0.698719\n",
      "13  TOR        1           1     0.667158\n",
      "10  NYK        0           1     0.585720\n",
      "11  ORL        0           0     0.040163\n",
      "6   DET        0           0     0.039957\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "## LOGISTIC REGRESSION MODEL ##\n",
    "###############################\n",
    "\n",
    "print(\"LOGISTIC REGRESSION MODEL FOR THE 2022 NBA SEASON IN THE EASTERN CONFERENCE\")\n",
    "print()\n",
    "# Creating a logistic regression object.\n",
    "east_logreg = LogisticRegression()\n",
    "# Fitting the model with the normalized x training and y training data.\n",
    "east_logreg.fit(x_train_normalized, np.ravel(y_train))\n",
    "# Getting the score from the normalized x training and y trianing data.\n",
    "east_logreg_train_score = east_logreg.score(x_train_normalized, y_train)\n",
    "# Printing out this score.\n",
    "print(\"Score for training data: \" + str(east_logreg_train_score))\n",
    "# Getting the score from the normalized x testing and y testing data.\n",
    "east_logreg_test_score = east_logreg.score(x_test_normalized, y_test)\n",
    "# Printing out this score.\n",
    "print(\"Score for testing data: \" + str(east_logreg_test_score))\n",
    "print()\n",
    "# Getting the names of the columns in the x training dataset.\n",
    "train_feature_names = x_train.columns\n",
    "print(\"Most important features for 2022 in the Eastern Conference\")\n",
    "# Calculating the coeffeicnt for the logistic regression model.\n",
    "coefficient_logreg = east_logreg.coef_\n",
    "# Getting the most important coefficient value which would be the first one in the list.\n",
    "importance_logreg = coefficient_logreg[0]\n",
    "# Taking the absolute value of this coeffficient.\n",
    "abs_importance_logreg = abs(importance_logreg)\n",
    "# Making a list of the feature names, the importance coeffeicient and the absolute value of this coefficient.\n",
    "importance_list_log = list(zip(train_feature_names, importance_logreg, abs_importance_logreg))\n",
    "# Sorting this list according to the absolute values of the coefficient.\n",
    "importance_list_log.sort(key=lambda x: x[2], reverse=True)\n",
    "for i in range(5):\n",
    "    print(importance_list_log[i])\n",
    "print()\n",
    "print(\"Predictions for which teams makes the playoffs for 2022 in the Eastern Conference\")\n",
    "# Getting the teams and whether they made it to the playoffs in our testing data. This will be the prediction that we would like to match.\n",
    "east_predictions_2022_LR = y_test_prediction[[\"TEAM\", \"PLAYOFF\"]]\n",
    "# Getting the probability of this predction, using the x data.\n",
    "logreg_probability = east_logreg.predict_proba(x_test_normalized)[:, 1].tolist()\n",
    "# Making a new predcition.\n",
    "logreg_prediction = east_logreg.predict(x_test_normalized).tolist()\n",
    "# Assigning the prediction value to the prediciotn column in the list.\n",
    "east_predictions_2022_LR[\"PREDICTION\"] = logreg_prediction\n",
    "# Assigning the probabilities to the column in the list.\n",
    "east_predictions_2022_LR[\"PROBABILITY\"] = logreg_probability\n",
    "# Sorting the list according to the porbability values.\n",
    "east_predictions_2022_LR = east_predictions_2022_LR.sort_values(\"PROBABILITY\", ascending=False)\n",
    "print(east_predictions_2022_LR)\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM MODEL FOR THE 2022 NBA SEASON IN THE EASTERN CONFERENCE\n",
      "\n",
      "Score for training data: 0.83\n",
      "Score for testing data: 0.8\n",
      "\n",
      "Most important features for 2022 in the Eastern Conference\n",
      "('PM', 6.619356851213325, 6.619356851213325)\n",
      "('TOV', -2.128579788769111, 2.128579788769111)\n",
      "('STL', 1.8783485152102481, 1.8783485152102481)\n",
      "('FGA', -1.8565698743163028, 1.8565698743163028)\n",
      "('FGPCT', 1.8146080083443126, 1.8146080083443126)\n",
      "\n",
      "Predictions for which teams makes the playoffs for 2022 in the Eastern Conference\n",
      "   TEAM  PLAYOFF  PREDICTION   PROBABILITY\n",
      "12  PHI        1           1  1.000000e+00\n",
      "4   CHI        1           1  1.000000e+00\n",
      "1   BKN        1           1  1.000000e+00\n",
      "9   MIL        1           1  1.000000e+00\n",
      "5   CLE        0           1  1.000000e+00\n",
      "3   CHA        0           1  1.000000e+00\n",
      "8   MIA        1           1  9.999999e-01\n",
      "2   BOS        1           1  9.999990e-01\n",
      "0   ATL        1           1  9.958712e-01\n",
      "13  TOR        1           1  9.609481e-01\n",
      "7   IND        0           1  9.534071e-01\n",
      "14  WAS        0           1  9.007125e-01\n",
      "10  NYK        0           1  7.674665e-01\n",
      "6   DET        0           0  1.856733e-07\n",
      "11  ORL        0           0  1.008950e-07\n"
     ]
    }
   ],
   "source": [
    "###############\n",
    "## SVM MODEL ##\n",
    "###############\n",
    "\n",
    "print(\"SVM MODEL FOR THE 2022 NBA SEASON IN THE EASTERN CONFERENCE\")\n",
    "print()\n",
    "# Making SVM model.\n",
    "east_svm = SVC(kernel=\"linear\", probability=True)\n",
    "# Fitting the data to the model.\n",
    "east_svm.fit(x_train_normalized, np.ravel(y_train))\n",
    "# Calculating the score from the x and y training data.\n",
    "east_svm_train_score = east_svm.score(x_train_normalized, y_train)\n",
    "# Printing the score for the training data.\n",
    "print(\"Score for training data: \" + str(east_svm_train_score))\n",
    "# Printing the score for the test data.\n",
    "east_svm_test_score = east_svm.score(x_test, y_test)\n",
    "# Printing the score for the training data.\n",
    "print(\"Score for testing data: \" + str(east_svm_test_score))\n",
    "print()\n",
    "# Getting the names of the columns in the x training dataset.\n",
    "train_feature_names_SVM = x_train.columns\n",
    "print(\"Most important features for 2022 in the Eastern Conference\")\n",
    "# Calculating the coefficient for the SVM.\n",
    "coefficient_svm = east_svm.coef_\n",
    "# Getting the most important coefficient value which would be the first one in the list.\n",
    "importance_svm = coefficient_svm[0]\n",
    "# Taking the absolute value of this coeffficient.\n",
    "abs_importance_svm = abs(importance_svm)\n",
    "# Making a list of the feature names, the importance coeffeicient and the absolute value of this coefficient.\n",
    "importance_list_svm = list(zip(train_feature_names_SVM, importance_svm, abs_importance_svm))\n",
    "# Sorting this list according to the absolute values of the coefficient.\n",
    "importance_list_svm.sort(key=lambda x: x[2], reverse=True)\n",
    "for i in range(5):\n",
    "    print(importance_list_svm[i])\n",
    "print()\n",
    "print(\"Predictions for which teams makes the playoffs for 2022 in the Eastern Conference\")\n",
    "# Getting the teams and whether they made it to the playoffs in our testing data. This will be the prediction that we would like to match.\n",
    "east_predictions_2022_SVM = y_test_prediction[[\"TEAM\", \"PLAYOFF\"]]\n",
    "# Getting the probability of this predction, using the x data.\n",
    "svm_probability = east_svm.predict_proba(x_test_normalized)[:, 1].tolist()\n",
    "# Making a new predcition.\n",
    "svm_prediction = east_svm.predict(x_test_normalized).tolist()\n",
    "# Assigning the prediction value to the prediciotn colum in the list.\n",
    "east_predictions_2022_SVM[\"PREDICTION\"] = svm_prediction\n",
    "# Assigning the probabilities to the column in the list.\n",
    "east_predictions_2022_SVM[\"PROBABILITY\"] = svm_probability\n",
    "# Sorting the list according to the porbability values.\n",
    "east_predictions_2022_SVM = east_predictions_2022_SVM.sort_values(\"PROBABILITY\", ascending=False)\n",
    "print(east_predictions_2022_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for training data: 1.0\n",
      "Score for testing data: 0.7333333333333333\n",
      "\n",
      "(0.3754902506143919, 'PM')\n",
      "(0.06095798170249698, 'FGPCT')\n",
      "(0.05649556207732384, 'FG3PCT')\n",
      "(0.05407501161569508, 'DREB')\n",
      "(0.04182972421969604, 'TOV')\n",
      "\n",
      "Predictions for which teams makes the playoffs for 2021 in the Eastern Conference\n",
      "\n",
      "   TEAM  PLAYOFF  PREDICTION  PROBABILITY\n",
      "3   CHA        0           1         0.66\n",
      "12  PHI        1           1         0.64\n",
      "9   MIL        1           1         0.62\n",
      "1   BKN        1           1         0.61\n",
      "4   CHI        1           1         0.59\n",
      "7   IND        0           1         0.59\n",
      "5   CLE        0           1         0.57\n",
      "8   MIA        1           1         0.56\n",
      "2   BOS        1           1         0.55\n",
      "14  WAS        0           1         0.55\n",
      "0   ATL        1           1         0.51\n",
      "13  TOR        1           1         0.51\n",
      "10  NYK        0           0         0.48\n",
      "11  ORL        0           0         0.43\n",
      "6   DET        0           0         0.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wq/kzy61k9n04l8p5wfbrlhxjlm0000gn/T/ipykernel_61536/2756196811.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  east_rf.fit(x_train_normalized, y_train)\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "## Random Forest Classifier Model ##\n",
    "####################################\n",
    "\n",
    "\n",
    "east_rf = RandomForestClassifier()\n",
    "east_rf.fit(x_train_normalized, y_train)\n",
    "# Getting the score from the normalized x training and y trianing data.\n",
    "east_rf_train_score = east_rf.score(x_train_normalized, y_train)\n",
    "# Printing out this score.\n",
    "print(\"Score for training data: \" + str(east_rf_train_score))\n",
    "# Getting the score from the normalized x testing and y testing data.\n",
    "east_rf_test_score = east_rf.score(x_test_normalized, y_test)\n",
    "# Printing out this score.\n",
    "print(\"Score for testing data: \" + str(east_rf_test_score))\n",
    "print()\n",
    "\n",
    "# Getting the names of the columns in the x training dataset.\n",
    "train_feature_names = x_train.columns\n",
    "\n",
    "# Getting the feature importances for all of the features trained in the model\n",
    "rf_importances = east_rf.feature_importances_\n",
    "# Making a list of the feature importances and feature names\n",
    "rf_importances = sorted(zip(rf_importances, train_feature_names), reverse=True)\n",
    "# Sorting this list to find the most important features from the model\n",
    "for i in range(5):\n",
    "    print(rf_importances[i])\n",
    "\n",
    "print()\n",
    "print(\"Predictions for which teams makes the playoffs for 2021 in the Eastern Conference\")\n",
    "print()\n",
    "# Getting the teams and whether they made it to the playoffs in our testing data. This will be the prediction that we would like to match.\n",
    "east_predictions_2022 = y_test_prediction[[\"TEAM\", \"PLAYOFF\"]]\n",
    "# Getting the probability of this predction, using the x data.\n",
    "rf_probability = east_rf.predict_proba(x_test_normalized)[:, 1].tolist()\n",
    "# Making a new predcition.\n",
    "rf_prediction = east_rf.predict(x_test_normalized).tolist()\n",
    "# Assinging the prediciotn value to the prediciotn colum in the list.\n",
    "east_predictions_2022[\"PREDICTION\"] = rf_prediction\n",
    "# Assigning the probabilities to the column in the list..\n",
    "east_predictions_2022[\"PROBABILITY\"] = rf_probability\n",
    "# Sorting the list according to the porbability values.\n",
    "east_predictions_2022 = east_predictions_2022.sort_values(\"PROBABILITY\", ascending=False)\n",
    "with open('./results/east_predictions_2022_RF', 'wb') as f:\n",
    "    pickle.dump(east_predictions_2022, f)\n",
    "    f.close()\n",
    "print(east_predictions_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 6, 'max_features': 10, 'min_samples_leaf': 20}\n",
      "Accuracy:  87.66666666666666\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "## Decision Tree Classifier Model ##\n",
    "####################################\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=6, max_features=10, min_samples_leaf=20)\n",
    "# Create dictionary of parameters to find the most optimal hyperparameters for the model\n",
    "params = {'max_depth': [2, 4, 6, 8, 10, 12],\n",
    "          'min_samples_leaf': [5, 10, 15, 20, 25, 30],\n",
    "          'max_features': [10, 12, 14, 16, 18, 20]}\n",
    "# Use GridSearchCV to find most optimal hyperparameters\n",
    "grid_search = GridSearchCV(clf, params, cv = 10, scoring = 'accuracy')\n",
    "# Fit the model to calculate the most optimal hyperparameters\n",
    "grid_search.fit(x_train_normalized, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(\"Accuracy: \", grid_search.best_score_ * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9364809235518072, 'PM')\n",
      "(0.032103779892645776, 'DREB')\n",
      "(0.023118101512993153, 'TOV')\n",
      "(0.005462775856840685, 'OREB')\n",
      "(0.002089595140941444, 'AST')\n",
      "\n",
      "Score for training data: 0.8766666666666667\n",
      "Score for testing data: 0.7333333333333333\n",
      "\n",
      "Predictions for which teams makes the playoffs for 2021 in the Eastern Conference\n",
      "\n",
      "   TEAM  PLAYOFF  PREDICTION  PROBABILITY\n",
      "1   BKN        1           1     1.000000\n",
      "2   BOS        1           1     1.000000\n",
      "4   CHI        1           1     1.000000\n",
      "5   CLE        0           1     1.000000\n",
      "7   IND        0           1     1.000000\n",
      "8   MIA        1           1     1.000000\n",
      "9   MIL        1           1     1.000000\n",
      "12  PHI        1           1     1.000000\n",
      "13  TOR        1           1     1.000000\n",
      "3   CHA        0           1     0.642857\n",
      "10  NYK        0           0     0.166667\n",
      "0   ATL        1           0     0.125000\n",
      "6   DET        0           0     0.125000\n",
      "11  ORL        0           0     0.125000\n",
      "14  WAS        0           0     0.125000\n"
     ]
    }
   ],
   "source": [
    "# Fit the model based on the optimized hyperparameters\n",
    "clf = DecisionTreeClassifier(max_depth=6, max_features=18, min_samples_leaf=20)\n",
    "clf.fit(x_train_normalized, y_train)\n",
    "\n",
    "train_feature_names = x_train.columns\n",
    "\n",
    "# Getting the feature importances for all of the features trained in the model\n",
    "dt_importances = clf.feature_importances_\n",
    "# Sorting this list to find the most important features from the model\n",
    "dt_importances = sorted(zip(dt_importances, train_feature_names), reverse=True)\n",
    "# Sorting this list to find the most important features from the model\n",
    "for i in range (5):\n",
    "    print (dt_importances[i])\n",
    "\n",
    "# Getting the score from the normalized x training and y trianing data.\n",
    "east_dt_train_score = clf.score(x_train_normalized, y_train)\n",
    "# east_logreg_train_score = east_logreg.score(x_train_normalized, y_train)\n",
    "# Printing out this score.\n",
    "print()\n",
    "print(\"Score for training data: \" + str(east_dt_train_score))\n",
    "# Getting the score from the normalized x testing and y testing data.\n",
    "east_dt_test_score = clf.score(x_test_normalized, y_test)\n",
    "# Printing out this score.\n",
    "print(\"Score for testing data: \" + str(east_dt_test_score))\n",
    "print()\n",
    "print(\"Predictions for which teams makes the playoffs for 2021 in the Eastern Conference\")\n",
    "print()\n",
    "# Getting the teams and whether they made it to the playoffs in our testing data. This will be the prediction that we would like to match.\n",
    "east_predictions_2022 = y_test_prediction[[\"TEAM\", \"PLAYOFF\"]]\n",
    "# Getting the probability of this predction, using the x data.\n",
    "dt_probability = clf.predict_proba(x_test_normalized)[:, 1].tolist()\n",
    "# rf_probability = rf.predict_proba(x_test_normalized)[:, 1].tolist()\n",
    "# Making a new predcition.\n",
    "dt_prediction = clf.predict(x_test_normalized).tolist()\n",
    "# Assinging the prediciotn value to the prediciotn colum in the list.\n",
    "east_predictions_2022[\"PREDICTION\"] = dt_prediction\n",
    "# Assigning the probabilities to the column in the list..\n",
    "east_predictions_2022[\"PROBABILITY\"] = dt_probability\n",
    "# Sorting the list according to the porbability values.\n",
    "east_predictions_2022 = east_predictions_2022.sort_values(\"PROBABILITY\", ascending=False)\n",
    "with open('./results/east_predictions_2022_DT', 'wb') as f:\n",
    "    pickle.dump(east_predictions_2022, f)\n",
    "    f.close()\n",
    "print(east_predictions_2022)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "## PREDICTING THE 2022 WESTERN CONFERENCE PLAYOFFS ##\n",
    "######################################################\n",
    "\n",
    "\n",
    "##############################################################\n",
    "## READING IN TRAINING DATA THAT HAS BEEN PREVIOSLY CLEANED ##\n",
    "##############################################################\n",
    "\n",
    "# Creating two empty lists that are used to store the data that is read in.\n",
    "x_train_list = []\n",
    "y_train_list = []\n",
    "# Iterating through the data for all the years.\n",
    "for i in range(2000, 2021):\n",
    "    # We ignore the year of 2004, as there seems to me something wrong with the formatting of the data in out dataset.\n",
    "    if i != 2004:\n",
    "        # Assembling in the name of the file that contains the x data that needs to be trained.\n",
    "        file_name = \"season_stats/west\" + str(i) + \".csv\"\n",
    "        # Reading the x data from the filename created above.\n",
    "        df_x = pd.read_csv(file_name, index_col=0)\n",
    "        # Sorting the data according to the values in the TEAM column.\n",
    "        df_x = df_x.sort_values(\"TEAM\")\n",
    "        # Resetting the index of the data.\n",
    "        df_x = df_x.reset_index()\n",
    "        # Dropping the TEAM column in the data.\n",
    "        df_x = df_x.drop(\"TEAM\", axis=1)\n",
    "        # Dropping the extra index column in the data.\n",
    "        df_x = df_x.drop(\"index\", axis=1)\n",
    "        # Appending the current round of data to the overall list holding all the x data.\n",
    "        x_train_list.append(df_x)\n",
    "        # Assembling in the name of the file that contains the y data that needs to be trained.\n",
    "        file_name = \"playoff_labels/west\" + str(i) + \"playoff.csv\"\n",
    "        # Reading the y data from the filename created above.\n",
    "        df_y = pd.read_csv(file_name, index_col=0)\n",
    "        # Sorting the data according to the values in the TEAM column.\n",
    "        df_y = df_y.sort_values(\"TEAM\")\n",
    "        # Resetting the index of the data.\n",
    "        df_y = df_y.reset_index()\n",
    "        # Dropping the TEAM column in the data.\n",
    "        df_y = df_y.drop(\"TEAM\", axis=1)\n",
    "        # Dropping the extra index column in the data.\n",
    "        df_y = df_y.drop(\"index\", axis=1)\n",
    "        # Appending the current round of data to the overall list holding all the y data.\n",
    "        y_train_list.append(df_y)\n",
    "\n",
    "# Concatentating the list of x data to a dataframe to hold all the x data.\n",
    "x_train = pd.concat(x_train_list)\n",
    "x_train = x_train.drop(\"MATCHUP\", axis=1)\n",
    "# x_train = x_train.drop(\"WLPCT\", axis=1)\n",
    "# Concatentating the list of y data to a dataframe to hold all the y data.\n",
    "y_train = pd.concat(y_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "## READING IN THE TEST DATA ##\n",
    "##############################\n",
    "\n",
    "# Assembling in the name of the file that contains the x data that needs to be tested against.\n",
    "x_test = pd.read_csv(\"season_stats/west2022.csv\", index_col=0)\n",
    "# Sorting the data according to the values in the TEAM column.\n",
    "x_test = x_test.sort_values(\"TEAM\")\n",
    "# Resetting the index of the data.\n",
    "x_test = x_test.reset_index()\n",
    "# Dropping the extra index column in the data.\n",
    "x_test = x_test.drop(\"index\", axis=1)\n",
    "x_test = x_test.drop(\"MATCHUP\", axis=1)\n",
    "# x_test = x_test.drop(\"WLPCT\", axis=1)\n",
    "# Assigning the test data to a variable that tells us that this is the prediction that should be made.\n",
    "x_test_prediction = x_test\n",
    "# Dropping the TEAM column in the data.\n",
    "x_test = x_test.drop(\"TEAM\", axis=1)\n",
    "# Assembling in the name of the file that contains the y data that needs to be tested against.\n",
    "y_test = pd.read_csv(\"playoff_labels/west2022playoff.csv\", index_col=0)\n",
    "# Sorting the data according to the values in the TEAM column.\n",
    "y_test = y_test.sort_values(\"TEAM\")\n",
    "# Resetting the index of the data.\n",
    "y_test = y_test.reset_index()\n",
    "# Dropping the extra index column in the data.\n",
    "y_test = y_test.drop(\"index\", axis=1)\n",
    "# Assigning the test data to a variable that tells us that this is the prediction that should be made.\n",
    "y_test_prediction = y_test\n",
    "# Dropping the TEAM column in the data.\n",
    "y_test = y_test.drop(\"TEAM\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "## STANDARDIZING THE X DATA ##\n",
    "##############################\n",
    "# Creating a scaler object.\n",
    "sc = StandardScaler()\n",
    "# Scaling the x training data.\n",
    "x_train_scaled = sc.fit_transform(x_train)\n",
    "# Scaling the x test data.\n",
    "x_test_scaled = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "## NORMALIZING THE X DATA ##\n",
    "############################\n",
    "# Normalizing the x scaled training data.\n",
    "a = preprocessing.normalize(x_train_scaled, axis = 0)\n",
    "# Creating a new dataframe to hold the saled, normalized x training data.\n",
    "x_train_normalized = pd.DataFrame(a, columns = x_train.columns)\n",
    "# Normalizing the x scaled testing data.\n",
    "b = preprocessing.normalize(x_test_scaled, axis = 0)\n",
    "# Creating a new dataframe to hold the saled, normalized x testing data.\n",
    "x_test_normalized = pd. DataFrame (b, columns = x_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION MODEL FOR THE 2022 NBA SEASON IN THE WESTERN CONFERENCE\n",
      "\n",
      "Score for training data: 0.8513513513513513\n",
      "Score for testing data: 0.7333333333333333\n",
      "\n",
      "Most important features for 2022 in the Western Conference\n",
      "('WLPCT', 3.9489615636330027, 3.9489615636330027)\n",
      "('PM', 3.7495904218670852, 3.7495904218670852)\n",
      "('FGPCT', 1.7897564091541547, 1.7897564091541547)\n",
      "('TOV', -1.2066008015955436, 1.2066008015955436)\n",
      "('AST', 1.0476024095510832, 1.0476024095510832)\n",
      "\n",
      "Predictions for which teams makes the playoffs for 2022 in the Western Conference\n",
      "   TEAM  PLAYOFF  PREDICTION  PROBABILITY\n",
      "10  PHX        1           1     0.994456\n",
      "14  UTA        1           1     0.989021\n",
      "2   GSW        1           1     0.987769\n",
      "6   MEM        1           1     0.962776\n",
      "5   LAL        0           1     0.748907\n",
      "1   DEN        1           1     0.746379\n",
      "0   DAL        1           1     0.598530\n",
      "13  SAS        0           1     0.549802\n",
      "4   LAC        0           0     0.471918\n",
      "7   MIN        1           0     0.379767\n",
      "11  POR        0           0     0.202633\n",
      "12  SAC        0           0     0.152103\n",
      "8   NOP        1           0     0.081074\n",
      "3   HOU        0           0     0.015401\n",
      "9   OKC        0           0     0.015180\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "## LOGISTIC REGRESSION MODEL ##\n",
    "###############################\n",
    "\n",
    "print(\"LOGISTIC REGRESSION MODEL FOR THE 2022 NBA SEASON IN THE WESTERN CONFERENCE\")\n",
    "print()\n",
    "# Creating a logistic regression object.\n",
    "west_logreg = LogisticRegression()\n",
    "# Fitting the model with the normalized x training and y training data.\n",
    "west_logreg.fit(x_train_normalized, np.ravel(y_train))\n",
    "# Getting the score from the normalized x training and y trianing data.\n",
    "west_logreg_train_score = west_logreg.score(x_train_normalized, y_train)\n",
    "# Printing out this score.\n",
    "print(\"Score for training data: \" + str(west_logreg_train_score))\n",
    "# Getting the score from the normalized x testing and y testing data.\n",
    "west_logreg_test_score = west_logreg.score(x_test_normalized, y_test)\n",
    "# Printing out this score.\n",
    "print(\"Score for testing data: \" + str(west_logreg_test_score))\n",
    "print()\n",
    "# Getting the names of the columns in the x training dataset.\n",
    "train_feature_names = x_train.columns\n",
    "print(\"Most important features for 2022 in the Western Conference\")\n",
    "# Calculating the coeffeicnt for the logistic regression model.\n",
    "coefficient_logreg = west_logreg.coef_\n",
    "# Getting the most important coefficient value which would be the first one in the list.\n",
    "importance_logreg = coefficient_logreg[0]\n",
    "# Taking the absolute value of this coeffficient.\n",
    "abs_importance_logreg = abs(importance_logreg)\n",
    "# Making a list of the feature names, the importance coeffeicient and the absolute value of this coefficient.\n",
    "importance_list_log = list(zip(train_feature_names, importance_logreg, abs_importance_logreg))\n",
    "# Sorting this list according to the absolute values of the coefficient.\n",
    "importance_list_log.sort(key=lambda x: x[2], reverse=True)\n",
    "for i in range(5):\n",
    "    print(importance_list_log[i])\n",
    "print()\n",
    "print(\"Predictions for which teams makes the playoffs for 2022 in the Western Conference\")\n",
    "# Getting the teams and whether they made it to the playoffs in our testing data. This will be the prediction that we would like to match.\n",
    "west_predictions_2022_LR = y_test_prediction[[\"TEAM\", \"PLAYOFF\"]]\n",
    "# Getting the probability of this predction, using the x data.\n",
    "logreg_probability = west_logreg.predict_proba(x_test_normalized)[:, 1].tolist()\n",
    "# Making a new predcition.\n",
    "logreg_prediction = west_logreg.predict(x_test_normalized).tolist()\n",
    "# Assigning the prediction value to the prediciotn column in the list.\n",
    "west_predictions_2022_LR[\"PREDICTION\"] = logreg_prediction\n",
    "# Assigning the probabilities to the column in the list.\n",
    "west_predictions_2022_LR[\"PROBABILITY\"] = logreg_probability\n",
    "# Sorting the list according to the porbability values.\n",
    "west_predictions_2022_LR = west_predictions_2022_LR.sort_values(\"PROBABILITY\", ascending=False)\n",
    "print(west_predictions_2022_LR)\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM MODEL FOR THE 2022 NBA SEASON IN THE WESTERN CONFERENCE\n",
      "\n",
      "Score for training data: 0.8513513513513513\n",
      "Score for testing data: 0.8666666666666667\n",
      "\n",
      "Most important features for 2022 in the Western Conference\n",
      "('WLPCT', 5.789988836508184, 5.789988836508184)\n",
      "('PM', 5.168403969489876, 5.168403969489876)\n",
      "('FGPCT', 2.228850098482319, 2.228850098482319)\n",
      "('TOV', -1.642327804536691, 1.642327804536691)\n",
      "('STL', 1.5457691263662912, 1.5457691263662912)\n",
      "\n",
      "Predictions for which teams makes the playoffs for 2022 in the Western Conference\n",
      "   TEAM  PLAYOFF  PREDICTION   PROBABILITY\n",
      "2   GSW        1           1  1.000000e+00\n",
      "10  PHX        1           1  1.000000e+00\n",
      "14  UTA        1           1  1.000000e+00\n",
      "6   MEM        1           1  1.000000e+00\n",
      "1   DEN        1           1  9.901427e-01\n",
      "5   LAL        0           1  9.338743e-01\n",
      "0   DAL        1           1  8.834405e-01\n",
      "13  SAS        0           0  2.079276e-01\n",
      "4   LAC        0           0  8.104037e-02\n",
      "7   MIN        1           0  1.582461e-02\n",
      "11  POR        0           0  7.935369e-05\n",
      "12  SAC        0           0  1.730505e-05\n",
      "8   NOP        1           0  1.197757e-06\n",
      "3   HOU        0           0  1.000000e-07\n",
      "9   OKC        0           0  1.000000e-07\n"
     ]
    }
   ],
   "source": [
    "###############\n",
    "## SVM MODEL ##\n",
    "###############\n",
    "\n",
    "print(\"SVM MODEL FOR THE 2022 NBA SEASON IN THE WESTERN CONFERENCE\")\n",
    "print()\n",
    "# Making SVM model.\n",
    "west_svm = SVC(kernel=\"linear\", probability=True)\n",
    "# Fitting the data to the model.\n",
    "west_svm.fit(x_train_normalized, np.ravel(y_train))\n",
    "# Calculating the score from the x and y training data.\n",
    "west_svm_train_score = west_svm.score(x_train_normalized, y_train)\n",
    "# Printing the score for the training data.\n",
    "print(\"Score for training data: \" + str(west_svm_train_score))\n",
    "# Printing the score for the test data.\n",
    "west_svm_test_score = west_svm.score(x_test, y_test)\n",
    "# Printing the score for the training data.\n",
    "print(\"Score for testing data: \" + str(west_svm_test_score))\n",
    "print()\n",
    "# Getting the names of the columns in the x training dataset.\n",
    "train_feature_names_SVM = x_train.columns\n",
    "print(\"Most important features for 2022 in the Western Conference\")\n",
    "# Calculating the coefficient for the SVM.\n",
    "coefficient_svm = west_svm.coef_\n",
    "# Getting the most important coefficient value which would be the first one in the list.\n",
    "importance_svm = coefficient_svm[0]\n",
    "# Taking the absolute value of this coeffficient.\n",
    "abs_importance_svm = abs(importance_svm)\n",
    "# Making a list of the feature names, the importance coeffeicient and the absolute value of this coefficient.\n",
    "importance_list_svm = list(zip(train_feature_names_SVM, importance_svm, abs_importance_svm))\n",
    "# Sorting this list according to the absolute values of the coefficient.\n",
    "importance_list_svm.sort(key=lambda x: x[2], reverse=True)\n",
    "for i in range(5):\n",
    "    print(importance_list_svm[i])\n",
    "print()\n",
    "print(\"Predictions for which teams makes the playoffs for 2022 in the Western Conference\")\n",
    "# Getting the teams and whether they made it to the playoffs in our testing data. This will be the prediction that we would like to match.\n",
    "west_predictions_2022_SVM = y_test_prediction[[\"TEAM\", \"PLAYOFF\"]]\n",
    "# Getting the probability of this predction, using the x data.\n",
    "svm_probability = west_svm.predict_proba(x_test_normalized)[:, 1].tolist()\n",
    "# Making a new predcition.\n",
    "svm_prediction = west_svm.predict(x_test_normalized).tolist()\n",
    "# Assigning the prediction value to the prediction column in the list.\n",
    "west_predictions_2022_SVM[\"PREDICTION\"] = svm_prediction\n",
    "# Assigning the probabilities to the column in the list.\n",
    "west_predictions_2022_SVM[\"PROBABILITY\"] = svm_probability\n",
    "# Sorting the list according to the probability values.\n",
    "west_predictions_2022_SVM = west_predictions_2022_SVM.sort_values(\"PROBABILITY\", ascending=False)\n",
    "print(west_predictions_2022_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for training data: 1.0\n",
      "Score for testing data: 0.8666666666666667\n",
      "\n",
      "(0.2814213143973307, 'PM')\n",
      "(0.2569024772496241, 'WLPCT')\n",
      "(0.0601612565253827, 'FGPCT')\n",
      "(0.036013231918746086, 'AST')\n",
      "(0.031539430738704105, 'DREB')\n",
      "\n",
      "Predictions for which teams makes the playoffs for 2021 in the Eastern Conference\n",
      "\n",
      "   TEAM  PLAYOFF  PREDICTION  PROBABILITY\n",
      "2   GSW        1           1         0.80\n",
      "10  PHX        1           1         0.77\n",
      "14  UTA        1           1         0.75\n",
      "1   DEN        1           1         0.70\n",
      "6   MEM        1           1         0.68\n",
      "0   DAL        1           1         0.65\n",
      "5   LAL        0           0         0.33\n",
      "7   MIN        1           0         0.30\n",
      "8   NOP        1           0         0.29\n",
      "9   OKC        0           0         0.28\n",
      "11  POR        0           0         0.27\n",
      "12  SAC        0           0         0.27\n",
      "4   LAC        0           0         0.25\n",
      "13  SAS        0           0         0.23\n",
      "3   HOU        0           0         0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wq/kzy61k9n04l8p5wfbrlhxjlm0000gn/T/ipykernel_61536/1499011923.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  west_rf.fit(x_train_normalized, y_train)\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "## Random Forest Classifier Model ##\n",
    "####################################\n",
    "\n",
    "\n",
    "west_rf = RandomForestClassifier()\n",
    "west_rf.fit(x_train_normalized, y_train)\n",
    "# Getting the score from the normalized x training and y trianing data.\n",
    "east_rf_train_score = west_rf.score(x_train_normalized, y_train)\n",
    "# Printing out this score.\n",
    "print(\"Score for training data: \" + str(east_rf_train_score))\n",
    "# Getting the score from the normalized x testing and y testing data.\n",
    "east_rf_test_score = west_rf.score(x_test_normalized, y_test)\n",
    "# Printing out this score.\n",
    "print(\"Score for testing data: \" + str(east_rf_test_score))\n",
    "print()\n",
    "\n",
    "# Getting the names of the columns in the x training dataset.\n",
    "train_feature_names = x_train.columns\n",
    "\n",
    "# Getting the feature importances for all of the features trained in the model\n",
    "rf_importances = west_rf.feature_importances_\n",
    "# Making a list of the feature importances and feature names\n",
    "rf_importances = sorted(zip(rf_importances, train_feature_names), reverse=True)\n",
    "# Sorting this list to find the most important features from the model\n",
    "for i in range(5):\n",
    "    print(rf_importances[i])\n",
    "\n",
    "print()\n",
    "print(\"Predictions for which teams makes the playoffs for 2021 in the Eastern Conference\")\n",
    "print()\n",
    "# Getting the teams and whether they made it to the playoffs in our testing data. This will be the prediction that we would like to match.\n",
    "west_predictions_2022 = y_test_prediction[[\"TEAM\", \"PLAYOFF\"]]\n",
    "# Getting the probability of this predction, using the x data.\n",
    "rf_probability = west_rf.predict_proba(x_test_normalized)[:, 1].tolist()\n",
    "# Making a new predcition.\n",
    "rf_prediction = west_rf.predict(x_test_normalized).tolist()\n",
    "# Assinging the prediciotn value to the prediciotn colum in the list.\n",
    "west_predictions_2022[\"PREDICTION\"] = rf_prediction\n",
    "# Assigning the probabilities to the column in the list..\n",
    "west_predictions_2022[\"PROBABILITY\"] = rf_probability\n",
    "# Sorting the list according to the porbability values.\n",
    "west_predictions_2022 = west_predictions_2022.sort_values(\"PROBABILITY\", ascending=False)\n",
    "with open('./results/west_predictions_2022_RF', 'wb') as f:\n",
    "    pickle.dump(west_predictions_2022, f)\n",
    "    f.close()\n",
    "print(west_predictions_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 4, 'max_features': 10, 'min_samples_leaf': 20}\n",
      "Accuracy:  88.49425287356321\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "## Decision Tree Classifier Model ##\n",
    "####################################\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "# Create dictionary of parameters to find the most optimal hyperparameters for the model\n",
    "params = {'max_depth': [2, 4, 6, 8, 10, 12],\n",
    "          'min_samples_leaf': [5, 10, 15, 20, 25, 30],\n",
    "          'max_features': [10, 12, 14, 16, 18, 20]}\n",
    "# Use GridSearchCV to find most optimal hyperparameters\n",
    "grid_search = GridSearchCV(clf, params, cv = 10, scoring = 'accuracy')\n",
    "# Fit the model to calculate the most optimal hyperparameters\n",
    "grid_search.fit(x_train_normalized, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(\"Accuracy: \", grid_search.best_score_ * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9645211145210472, 'WLPCT')\n",
      "(0.016873520771006068, 'STL')\n",
      "(0.010371711516909583, 'OREB')\n",
      "(0.00569555022391009, 'DREB')\n",
      "(0.002538102967127175, 'FTPCT')\n",
      "\n",
      "Score for training data: 0.8885135135135135\n",
      "Score for testing data: 0.8666666666666667\n",
      "\n",
      "Predictions for which teams makes the playoffs for 2021 in the Eastern Conference\n",
      "\n",
      "   TEAM  PLAYOFF  PREDICTION  PROBABILITY\n",
      "0   DAL        1           1     1.000000\n",
      "1   DEN        1           1     1.000000\n",
      "10  PHX        1           1     1.000000\n",
      "14  UTA        1           1     1.000000\n",
      "2   GSW        1           1     0.916667\n",
      "6   MEM        1           1     0.916667\n",
      "5   LAL        0           0     0.161290\n",
      "3   HOU        0           0     0.000000\n",
      "4   LAC        0           0     0.000000\n",
      "7   MIN        1           0     0.000000\n",
      "8   NOP        1           0     0.000000\n",
      "9   OKC        0           0     0.000000\n",
      "11  POR        0           0     0.000000\n",
      "12  SAC        0           0     0.000000\n",
      "13  SAS        0           0     0.000000\n"
     ]
    }
   ],
   "source": [
    "# Fit the model based on the optimized hyperparameters\n",
    "clf = DecisionTreeClassifier(max_depth=6, max_features=10, min_samples_leaf=20)\n",
    "clf.fit(x_train_normalized, y_train)\n",
    "\n",
    "train_feature_names = x_train.columns\n",
    "\n",
    "# Getting the feature importances for all of the features trained in the model\n",
    "dt_importances = clf.feature_importances_\n",
    "# Sorting this list to find the most important features from the model\n",
    "dt_importances = sorted(zip(dt_importances, train_feature_names), reverse=True)\n",
    "# Sorting this list to find the most important features from the model\n",
    "for i in range (5):\n",
    "    print (dt_importances[i])\n",
    "\n",
    "# Getting the score from the normalized x training and y trianing data.\n",
    "east_dt_train_score = clf.score(x_train_normalized, y_train)\n",
    "# east_logreg_train_score = east_logreg.score(x_train_normalized, y_train)\n",
    "# Printing out this score.\n",
    "print()\n",
    "print(\"Score for training data: \" + str(east_dt_train_score))\n",
    "# Getting the score from the normalized x testing and y testing data.\n",
    "east_dt_test_score = clf.score(x_test_normalized, y_test)\n",
    "# Printing out this score.\n",
    "print(\"Score for testing data: \" + str(east_dt_test_score))\n",
    "print()\n",
    "print(\"Predictions for which teams makes the playoffs for 2021 in the Eastern Conference\")\n",
    "print()\n",
    "# Getting the teams and whether they made it to the playoffs in our testing data. This will be the prediction that we would like to match.\n",
    "west_predictions_2022 = y_test_prediction[[\"TEAM\", \"PLAYOFF\"]]\n",
    "# Getting the probability of this predction, using the x data.\n",
    "dt_probability = clf.predict_proba(x_test_normalized)[:, 1].tolist()\n",
    "# rf_probability = rf.predict_proba(x_test_normalized)[:, 1].tolist()\n",
    "# Making a new predcition.\n",
    "dt_prediction = clf.predict(x_test_normalized).tolist()\n",
    "# Assinging the prediciotn value to the prediciotn colum in the list.\n",
    "west_predictions_2022[\"PREDICTION\"] = dt_prediction\n",
    "# Assigning the probabilities to the column in the list..\n",
    "west_predictions_2022[\"PROBABILITY\"] = dt_probability\n",
    "# Sorting the list according to the porbability values.\n",
    "west_predictions_2022 = west_predictions_2022.sort_values(\"PROBABILITY\", ascending=False)\n",
    "with open('./results/ewest_predictions_2022_DT', 'wb') as f:\n",
    "    pickle.dump(west_predictions_2022, f)\n",
    "    f.close()\n",
    "print(west_predictions_2022)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
