{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS THE MAIN FILE USED TO CREATE ALL MODELS\n",
    "# We have so far implemented two models: Logistic Regression and SVM.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "## TRAINED MODELS FOR PREDICTING THE 2021 PLAYOFFS ##\n",
    "#####################################################\n",
    "\n",
    "\n",
    "#####################################################\n",
    "## PREDICTING THE 2021 EASTERN CONFERENCE PLAYOFFS ##\n",
    "######################################################\n",
    "\n",
    "\n",
    "##############################################################\n",
    "## READING IN TRAINING DATA THAT HAS BEEN PREVIOSLY CLEANED ##\n",
    "##############################################################\n",
    "\n",
    "# Creating two empty lists that are used to store the data that is read in.\n",
    "x_train_list = []\n",
    "y_train_list = []\n",
    "# Iterating through the data for all the years.\n",
    "for i in range(2000, 2021):\n",
    "    # We ignore the year of 2004, as there seems to me something wrong with the formatting of the data in out dataset.\n",
    "    if i != 2004:\n",
    "        # Assembling in the name of the file that contains the x data that needs to be trained.\n",
    "        file_name = \"season_stats/east\" + str(i) + \".csv\"\n",
    "        # Reading the x data from the filename created above.\n",
    "        df_x = pd.read_csv(file_name, index_col=0)\n",
    "        # Sorting the data according to the values in the TEAM column.\n",
    "        df_x = df_x.sort_values(\"TEAM\")\n",
    "        # Resetting the index of the data.\n",
    "        df_x = df_x.reset_index()\n",
    "        # Dropping the TEAM column in the data.\n",
    "        df_x = df_x.drop(\"TEAM\", axis=1)\n",
    "        # Dropping the extra index column in the data.\n",
    "        df_x = df_x.drop(\"index\", axis=1)\n",
    "        # Appending the current round of data to the overall list holding all the x data.\n",
    "        x_train_list.append(df_x)\n",
    "        # Assembling in the name of the file that contains the y data that needs to be trained.\n",
    "        file_name = \"playoff_labels/east\" + str(i) + \"playoff.csv\"\n",
    "        # Reading the y data from the filename created above.\n",
    "        df_y = pd.read_csv(file_name, index_col=0)\n",
    "        # Sorting the data according to the values in the TEAM column.\n",
    "        df_y = df_y.sort_values(\"TEAM\")\n",
    "        # Resetting the index of the data.\n",
    "        df_y = df_y.reset_index()\n",
    "        # Dropping the TEAM column in the data.\n",
    "        df_y = df_y.drop(\"TEAM\", axis=1)\n",
    "        # Dropping the extra index column in the data.\n",
    "        df_y = df_y.drop(\"index\", axis=1)\n",
    "        # Appending the current round of data to the overall list holding all the y data.\n",
    "        y_train_list.append(df_y)\n",
    "\n",
    "# Concatentating the list of x data to a dataframe to hold all the x data.\n",
    "x_train = pd.concat(x_train_list)\n",
    "# Concatentating the list of y data to a dataframe to hold all the y data.\n",
    "y_train = pd.concat(y_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "## READING IN THE TEST DATA ##\n",
    "##############################\n",
    "\n",
    "# Assembling in the name of the file that contains the x data that needs to be tested against.\n",
    "x_test = pd.read_csv(\"season_stats/east2021.csv\", index_col=0)\n",
    "# Sorting the data according to the values in the TEAM column.\n",
    "x_test = x_test.sort_values(\"TEAM\")\n",
    "# Resetting the index of the data.\n",
    "x_test = x_test.reset_index()\n",
    "# Dropping the extra index column in the data.\n",
    "x_test = x_test.drop(\"index\", axis=1)\n",
    "# Assigning the test data to a variable that tells us that this is the prediction that should be made.\n",
    "x_test_prediction = x_test\n",
    "# Dropping the TEAM column in the data.\n",
    "x_test = x_test.drop(\"TEAM\", axis=1)\n",
    "# Assembling in the name of the file that contains the y data that needs to be tested against.\n",
    "y_test = pd.read_csv(\"playoff_labels/east2021playoff.csv\", index_col=0)\n",
    "# Sorting the data according to the values in the TEAM column.\n",
    "y_test = y_test.sort_values(\"TEAM\")\n",
    "# Resetting the index of the data.\n",
    "y_test = y_test.reset_index()\n",
    "# Dropping the extra index column in the data.\n",
    "y_test = y_test.drop(\"index\", axis=1)\n",
    "# Assigning the test data to a variable that tells us that this is the prediction that should be made.\n",
    "y_test_prediction = y_test\n",
    "# Dropping the TEAM column in the data.\n",
    "y_test = y_test.drop(\"TEAM\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "## STANDARDIZING THE X DATA ##\n",
    "##############################\n",
    "# Creating a scaler object.\n",
    "sc = StandardScaler()\n",
    "# Scaling the x training data.\n",
    "x_train_scaled = sc.fit_transform(x_train)\n",
    "# Scaling the x test data.\n",
    "x_test_scaled = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "## NORMALIZING THE X DATA ##\n",
    "############################\n",
    "# Normalizing the x scaled training data.\n",
    "a = preprocessing.normalize(x_train_scaled, axis = 0)\n",
    "# Creating a new dataframe to hold the saled, normalized x training data.\n",
    "x_train_normalized = pd.DataFrame(a, columns = x_train.columns)\n",
    "# Normalizing the x scaled testing data.\n",
    "b = preprocessing.normalize(x_test_scaled, axis = 0)\n",
    "# Creating a new dataframe to hold the saled, normalized x testing data.\n",
    "x_test_normalized = pd. DataFrame (b, columns = x_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "## LOGISTIC REGRESSION MODEL ##\n",
    "###############################\n",
    "\n",
    "print(\"LOGISTIC REGRESSION MODEL FOR THE 2021 NBA SEASON IN THE EASTERN CONFERENCE\")\n",
    "print()\n",
    "# Creating a logistic regression object.\n",
    "east_logreg = LogisticRegression()\n",
    "# Fitting the model with the normalized x training and y training data.\n",
    "east_logreg.fit(x_train_normalized, np.ravel(y_train))\n",
    "# Getting the score from the normalized x training and y trianing data.\n",
    "east_logreg_train_score = east_logreg.score(x_train_normalized, y_train)\n",
    "# Printing out this score.\n",
    "print(\"Score for training data: \" + str(east_logreg_train_score))\n",
    "# Getting the score from the normalized x testing and y testing data.\n",
    "east_logreg_test_score = east_logreg.score(x_test_normalized, y_test)\n",
    "# Printing out this score.\n",
    "print(\"Score for testing data: \" + str(east_logreg_test_score))\n",
    "print()\n",
    "# Getting the names of the columns in the x training dataset.\n",
    "train_feature_names = x_train.columns\n",
    "print(\"Most important features for 2021 in the Eastern Conference\")\n",
    "# Calculating the coeffeicnt for the logistic regression model. \n",
    "coefficient_logreg = east_logreg.coef_\n",
    "# Getting the most important coefficient value which would be the first one in the list.\n",
    "importance_logreg = coefficient_logreg[0]\n",
    "# Taking the absolute value of this coeffficient.\n",
    "abs_importance_logreg = abs(importance_logreg)\n",
    "# Making a list of the feature names, the importance coeffeicient and the absolute value of this coefficient.\n",
    "importance_list_log = list(zip(train_feature_names, importance_logreg, abs_importance_logreg))\n",
    "# Sorting this list according to the absolute values of the coefficient.\n",
    "importance_list_log.sort(key=lambda x: x[2], reverse=True)\n",
    "for i in range(5):\n",
    "    print(importance_list_log[i])\n",
    "print()\n",
    "print(\"Predictions for which teams makes the playoffs for 2021 in the Eastern Conference\")\n",
    "# Getting the teams and whether they made it to the playoffs in our testing data. This will be the prediction that we would like to match.\n",
    "east_predictions_2021_LR = y_test_prediction[[\"TEAM\", \"PLAYOFF\"]]\n",
    "# Getting the probability of this predction, using the x data.\n",
    "logreg_probability = east_logreg.predict_proba(x_test_normalized)[:, 1].tolist()\n",
    "# Making a new predcition.\n",
    "logreg_prediction = east_logreg.predict(x_test_normalized).tolist()\n",
    "# Assigning the prediction value to the prediciotn column in the list.\n",
    "east_predictions_2021_LR[\"PREDICTION\"] = logreg_prediction\n",
    "# Assigning the probabilities to the column in the list.\n",
    "east_predictions_2021_LR[\"PROBABILITY\"] = logreg_probability\n",
    "# Sorting the list according to the porbability values.\n",
    "east_predictions_2021_LR = east_predictions_2021_LR.sort_values(\"PROBABILITY\", ascending=False)\n",
    "print(east_predictions_2021_LR)\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "## SVM MODEL ##\n",
    "###############\n",
    "\n",
    "print(\"SVM MODEL FOR THE 2021 NBA SEASON IN THE EASTERN CONFERENCE\")\n",
    "print()\n",
    "# Making SVM model.\n",
    "east_svm = SVC(kernel=\"linear\", probability=True)\n",
    "# Fitting the data to the model.\n",
    "east_svm.fit(x_train_normalized, np.ravel(y_train))\n",
    "# Calculating the score from the x and y training data.\n",
    "east_svm_train_score = east_svm.score(x_train_normalized, y_train)\n",
    "# Printing the score for the training data.\n",
    "print(\"Score for training data: \" + str(east_svm_train_score))\n",
    "# Printing the score for the test data.\n",
    "east_svm_test_score = east_svm.score(x_test, y_test)\n",
    "# Printing the score for the training data.\n",
    "print(\"Score for testing data: \" + str(east_svm_test_score))\n",
    "print()\n",
    "# Getting the names of the columns in the x training dataset.\n",
    "train_feature_names_SVM = x_train.columns\n",
    "print(\"Most important features for 2021 in the Eastern Conference\")\n",
    "# Calculating the coefficient for the SVM.\n",
    "coefficient_svm = east_svm.coef_\n",
    "# Getting the most important coefficient value which would be the first one in the list.\n",
    "importance_svm = coefficient_svm[0]\n",
    "# Taking the absolute value of this coeffficient.\n",
    "abs_importance_svm = abs(importance_svm)\n",
    "# Making a list of the feature names, the importance coeffeicient and the absolute value of this coefficient.\n",
    "importance_list_svm = list(zip(train_feature_names_SVM, importance_svm, abs_importance_svm))\n",
    "# Sorting this list according to the absolute values of the coefficient.\n",
    "importance_list_svm.sort(key=lambda x: x[2], reverse=True)\n",
    "for i in range(5):\n",
    "    print(importance_list_svm[i])\n",
    "print()\n",
    "print(\"Predictions for which teams makes the playoffs for 2021 in the Eastern Conference\")\n",
    "# Getting the teams and whether they made it to the playoffs in our testing data. This will be the prediction that we would like to match.\n",
    "east_predictions_2021_SVM = y_test_prediction[[\"TEAM\", \"PLAYOFF\"]]\n",
    "# Getting the probability of this predction, using the x data.\n",
    "svm_probability = east_svm.predict_proba(x_test_normalized)[:, 1].tolist()\n",
    "# Making a new predcition.\n",
    "svm_prediction = east_svm.predict(x_test_normalized).tolist()\n",
    "# Assigning the prediction value to the prediciotn colum in the list.\n",
    "east_predictions_2021_SVM[\"PREDICTION\"] = svm_prediction\n",
    "# Assigning the probabilities to the column in the list.\n",
    "east_predictions_2021_SVM[\"PROBABILITY\"] = svm_probability\n",
    "# Sorting the list according to the porbability values.\n",
    "east_predictions_2021_SVM = east_predictions_2021_SVM.sort_values(\"PROBABILITY\", ascending=False)\n",
    "print(east_predictions_2021_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "## PREDICTING THE 2021 WESTERN CONFERENCE PLAYOFFS ##\n",
    "######################################################\n",
    "\n",
    "\n",
    "##############################################################\n",
    "## READING IN TRAINING DATA THAT HAS BEEN PREVIOSLY CLEANED ##\n",
    "##############################################################\n",
    "\n",
    "# Creating two empty lists that are used to store the data that is read in.\n",
    "x_train_list = []\n",
    "y_train_list = []\n",
    "# Iterating through the data for all the years.\n",
    "for i in range(2000, 2021):\n",
    "    # We ignore the year of 2004, as there seems to me something wrong with the formatting of the data in out dataset.\n",
    "    if i != 2004:\n",
    "        # Assembling in the name of the file that contains the x data that needs to be trained.\n",
    "        file_name = \"season_stats/west\" + str(i) + \".csv\"\n",
    "        # Reading the x data from the filename created above.\n",
    "        df_x = pd.read_csv(file_name, index_col=0)\n",
    "        # Sorting the data according to the values in the TEAM column.\n",
    "        df_x = df_x.sort_values(\"TEAM\")\n",
    "        # Resetting the index of the data.\n",
    "        df_x = df_x.reset_index()\n",
    "        # Dropping the TEAM column in the data.\n",
    "        df_x = df_x.drop(\"TEAM\", axis=1)\n",
    "        # Dropping the extra index column in the data.\n",
    "        df_x = df_x.drop(\"index\", axis=1)\n",
    "        # Appending the current round of data to the overall list holding all the x data.\n",
    "        x_train_list.append(df_x)\n",
    "        # Assembling in the name of the file that contains the y data that needs to be trained.\n",
    "        file_name = \"playoff_labels/west\" + str(i) + \"playoff.csv\"\n",
    "        # Reading the y data from the filename created above.\n",
    "        df_y = pd.read_csv(file_name, index_col=0)\n",
    "        # Sorting the data according to the values in the TEAM column.\n",
    "        df_y = df_y.sort_values(\"TEAM\")\n",
    "        # Resetting the index of the data.\n",
    "        df_y = df_y.reset_index()\n",
    "        # Dropping the TEAM column in the data.\n",
    "        df_y = df_y.drop(\"TEAM\", axis=1)\n",
    "        # Dropping the extra index column in the data.\n",
    "        df_y = df_y.drop(\"index\", axis=1)\n",
    "        # Appending the current round of data to the overall list holding all the y data.\n",
    "        y_train_list.append(df_y)\n",
    "\n",
    "# Concatentating the list of x data to a dataframe to hold all the x data.\n",
    "x_train = pd.concat(x_train_list)\n",
    "# Concatentating the list of y data to a dataframe to hold all the y data.\n",
    "y_train = pd.concat(y_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "## READING IN THE TEST DATA ##\n",
    "##############################\n",
    "\n",
    "# Assembling in the name of the file that contains the x data that needs to be tested against.\n",
    "x_test = pd.read_csv(\"season_stats/west2021.csv\", index_col=0)\n",
    "# Sorting the data according to the values in the TEAM column.\n",
    "x_test = x_test.sort_values(\"TEAM\")\n",
    "# Resetting the index of the data.\n",
    "x_test = x_test.reset_index()\n",
    "# Dropping the extra index column in the data.\n",
    "x_test = x_test.drop(\"index\", axis=1)\n",
    "# Assigning the test data to a variable that tells us that this is the prediction that should be made.\n",
    "x_test_prediction = x_test\n",
    "# Dropping the TEAM column in the data.\n",
    "x_test = x_test.drop(\"TEAM\", axis=1)\n",
    "# Assembling in the name of the file that contains the y data that needs to be tested against.\n",
    "y_test = pd.read_csv(\"playoff_labels/west2021playoff.csv\", index_col=0)\n",
    "# Sorting the data according to the values in the TEAM column.\n",
    "y_test = y_test.sort_values(\"TEAM\")\n",
    "# Resetting the index of the data.\n",
    "y_test = y_test.reset_index()\n",
    "# Dropping the extra index column in the data.\n",
    "y_test = y_test.drop(\"index\", axis=1)\n",
    "# Assigning the test data to a variable that tells us that this is the prediction that should be made.\n",
    "y_test_prediction = y_test\n",
    "# Dropping the TEAM column in the data.\n",
    "y_test = y_test.drop(\"TEAM\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "## STANDARDIZING THE X DATA ##\n",
    "##############################\n",
    "# Creating a scaler object.\n",
    "sc = StandardScaler()\n",
    "# Scaling the x training data.\n",
    "x_train_scaled = sc.fit_transform(x_train)\n",
    "# Scaling the x test data.\n",
    "x_test_scaled = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "## NORMALIZING THE X DATA ##\n",
    "############################\n",
    "# Normalizing the x scaled training data.\n",
    "a = preprocessing.normalize(x_train_scaled, axis = 0)\n",
    "# Creating a new dataframe to hold the saled, normalized x training data.\n",
    "x_train_normalized = pd.DataFrame(a, columns = x_train.columns)\n",
    "# Normalizing the x scaled testing data.\n",
    "b = preprocessing.normalize(x_test_scaled, axis = 0)\n",
    "# Creating a new dataframe to hold the saled, normalized x testing data.\n",
    "x_test_normalized = pd. DataFrame (b, columns = x_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "## LOGISTIC REGRESSION MODEL ##\n",
    "###############################\n",
    "\n",
    "print(\"LOGISTIC REGRESSION MODEL FOR THE 2021 NBA SEASON IN THE WESTERN CONFERENCE\")\n",
    "print()\n",
    "# Creating a logistic regression object.\n",
    "west_logreg = LogisticRegression()\n",
    "# Fitting the model with the normalized x training and y training data.\n",
    "west_logreg.fit(x_train_normalized, np.ravel(y_train))\n",
    "# Getting the score from the normalized x training and y trianing data.\n",
    "west_logreg_train_score = west_logreg.score(x_train_normalized, y_train)\n",
    "# Printing out this score.\n",
    "print(\"Score for training data: \" + str(west_logreg_train_score))\n",
    "# Getting the score from the normalized x testing and y testing data.\n",
    "west_logreg_test_score = west_logreg.score(x_test_normalized, y_test)\n",
    "# Printing out this score.\n",
    "print(\"Score for testing data: \" + str(west_logreg_test_score))\n",
    "print()\n",
    "# Getting the names of the columns in the x training dataset.\n",
    "train_feature_names = x_train.columns\n",
    "print(\"Most important features for 2021 in the Western Conference\")\n",
    "# Calculating the coeffeicnt for the logistic regression model.\n",
    "coefficient_logreg = west_logreg.coef_\n",
    "# Getting the most important coefficient value which would be the first one in the list.\n",
    "importance_logreg = coefficient_logreg[0]\n",
    "# Taking the absolute value of this coeffficient.\n",
    "abs_importance_logreg = abs(importance_logreg)\n",
    "# Making a list of the feature names, the importance coeffeicient and the absolute value of this coefficient.\n",
    "importance_list_log = list(zip(train_feature_names, importance_logreg, abs_importance_logreg))\n",
    "# Sorting this list according to the absolute values of the coefficient.\n",
    "importance_list_log.sort(key=lambda x: x[2], reverse=True)\n",
    "for i in range(5):\n",
    "    print(importance_list_log[i])\n",
    "print()\n",
    "print(\"Predictions for which teams makes the playoffs for 2021 in the Western Conference\")\n",
    "# Getting the teams and whether they made it to the playoffs in our testing data. This will be the prediction that we would like to match.\n",
    "west_predictions_2021_LR = y_test_prediction[[\"TEAM\", \"PLAYOFF\"]]\n",
    "# Getting the probability of this predction, using the x data.\n",
    "logreg_probability = west_logreg.predict_proba(x_test_normalized)[:, 1].tolist()\n",
    "# Making a new predcition.\n",
    "logreg_prediction = west_logreg.predict(x_test_normalized).tolist()\n",
    "# Assigning the prediction value to the prediciotn column in the list.\n",
    "west_predictions_2021_LR[\"PREDICTION\"] = logreg_prediction\n",
    "# Assigning the probabilities to the column in the list.\n",
    "west_predictions_2021_LR[\"PROBABILITY\"] = logreg_probability\n",
    "# Sorting the list according to the porbability values.\n",
    "west_predictions_2021_LR = west_predictions_2021_LR.sort_values(\"PROBABILITY\", ascending=False)\n",
    "print(west_predictions_2021_LR)\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "## SVM MODEL ##\n",
    "###############\n",
    "\n",
    "print(\"SVM MODEL FOR THE 2021 NBA SEASON IN THE WESTERN CONFERENCE\")\n",
    "print()\n",
    "# Making SVM model.\n",
    "west_svm = SVC(kernel=\"linear\", probability=True)\n",
    "# Fitting the data to the model.\n",
    "west_svm.fit(x_train_normalized, np.ravel(y_train))\n",
    "# Calculating the score from the x and y training data.\n",
    "west_svm_train_score = west_svm.score(x_train_normalized, y_train)\n",
    "# Printing the score for the training data.\n",
    "print(\"Score for training data: \" + str(west_svm_train_score))\n",
    "# Printing the score for the test data.\n",
    "west_svm_test_score = west_svm.score(x_test, y_test)\n",
    "# Printing the score for the training data.\n",
    "print(\"Score for testing data: \" + str(west_svm_test_score))\n",
    "print()\n",
    "# Getting the names of the columns in the x training dataset.\n",
    "train_feature_names_SVM = x_train.columns\n",
    "print(\"Most important features for 2021 in the Western Conference\")\n",
    "# Calculating the coefficient for the SVM.\n",
    "coefficient_svm = west_svm.coef_\n",
    "# Getting the most important coefficient value which would be the first one in the list.\n",
    "importance_svm = coefficient_svm[0]\n",
    "# Taking the absolute value of this coeffficient.\n",
    "abs_importance_svm = abs(importance_svm)\n",
    "# Making a list of the feature names, the importance coeffeicient and the absolute value of this coefficient.\n",
    "importance_list_svm = list(zip(train_feature_names_SVM, importance_svm, abs_importance_svm))\n",
    "# Sorting this list according to the absolute values of the coefficient.\n",
    "importance_list_svm.sort(key=lambda x: x[2], reverse=True)\n",
    "for i in range(5):\n",
    "    print(importance_list_svm[i])\n",
    "print()\n",
    "print(\"Predictions for which teams makes the playoffs for 2021 in the Western Conference\")\n",
    "# Getting the teams and whether they made it to the playoffs in our testing data. This will be the prediction that we would like to match.\n",
    "west_predictions_2021_SVM = y_test_prediction[[\"TEAM\", \"PLAYOFF\"]]\n",
    "# Getting the probability of this predction, using the x data.\n",
    "svm_probability = west_svm.predict_proba(x_test_normalized)[:, 1].tolist()\n",
    "# Making a new predcition.\n",
    "svm_prediction = west_svm.predict(x_test_normalized).tolist()\n",
    "# Assigning the prediction value to the prediction column in the list.\n",
    "west_predictions_2021_SVM[\"PREDICTION\"] = svm_prediction\n",
    "# Assigning the probabilities to the column in the list.\n",
    "west_predictions_2021_SVM[\"PROBABILITY\"] = svm_probability\n",
    "# Sorting the list according to the probability values.\n",
    "west_predictions_2021_SVM = west_predictions_2021_SVM.sort_values(\"PROBABILITY\", ascending=False)\n",
    "print(west_predictions_2021_SVM)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
