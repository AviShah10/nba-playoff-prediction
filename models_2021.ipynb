{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS THE MAIN FILE USED TO CREATE ALL MODELS\n",
    "# We have so far implemented two models: Logistic Regression and SVM.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "## TRAINED MODELS FOR PREDICTING THE 2021 PLAYOFFS ##\n",
    "#####################################################\n",
    "\n",
    "\n",
    "#####################################################\n",
    "## PREDICTING THE 2021 EASTERN CONFERENCE PLAYOFFS ##\n",
    "######################################################\n",
    "\n",
    "\n",
    "##############################################################\n",
    "## READING IN TRAINING DATA THAT HAS BEEN PREVIOSLY CLEANED ##\n",
    "##############################################################\n",
    "\n",
    "# Creating two empty lists that are used to store the data that is read in.\n",
    "x_train_list = []\n",
    "y_train_list = []\n",
    "# Iterating through the data for all the years.\n",
    "for i in range(2000, 2021):\n",
    "    # We ignore the year of 2004, as there seems to me something wrong with the formatting of the data in out dataset.\n",
    "    if i != 2004:\n",
    "        # Assembling in the name of the file that contains the x data that needs to be trained.\n",
    "        file_name = \"season_stats/east\" + str(i) + \".csv\"\n",
    "        # Reading the x data from the filename created above.\n",
    "        df_x = pd.read_csv(file_name, index_col=0)\n",
    "        # Sorting the data according to the values in the TEAM column.\n",
    "        df_x = df_x.sort_values(\"TEAM\")\n",
    "        # Resetting the index of the data.\n",
    "        df_x = df_x.reset_index()\n",
    "        # Dropping the TEAM column in the data.\n",
    "        df_x = df_x.drop(\"TEAM\", axis=1)\n",
    "        # Dropping the extra index column in the data.\n",
    "        df_x = df_x.drop(\"index\", axis=1)\n",
    "        # Appending the current round of data to the overall list holding all the x data.\n",
    "        x_train_list.append(df_x)\n",
    "        # Assembling in the name of the file that contains the y data that needs to be trained.\n",
    "        file_name = \"playoff_labels/east\" + str(i) + \"playoff.csv\"\n",
    "        # Reading the y data from the filename created above.\n",
    "        df_y = pd.read_csv(file_name, index_col=0)\n",
    "        # Sorting the data according to the values in the TEAM column.\n",
    "        df_y = df_y.sort_values(\"TEAM\")\n",
    "        # Resetting the index of the data.\n",
    "        df_y = df_y.reset_index()\n",
    "        # Dropping the TEAM column in the data.\n",
    "        df_y = df_y.drop(\"TEAM\", axis=1)\n",
    "        # Dropping the extra index column in the data.\n",
    "        df_y = df_y.drop(\"index\", axis=1)\n",
    "        # Appending the current round of data to the overall list holding all the y data.\n",
    "        y_train_list.append(df_y)\n",
    "\n",
    "# Concatentating the list of x data to a dataframe to hold all the x data.\n",
    "x_train = pd.concat(x_train_list)\n",
    "x_train = x_train.drop(\"MATCHUP\", axis=1)\n",
    "x_train = x_train.drop(\"WLPCT\", axis=1)\n",
    "# Concatentating the list of y data to a dataframe to hold all the y data.\n",
    "y_train = pd.concat(y_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "## READING IN THE TEST DATA ##\n",
    "##############################\n",
    "\n",
    "# Assembling in the name of the file that contains the x data that needs to be tested against.\n",
    "x_test = pd.read_csv(\"season_stats/east2021.csv\", index_col=0)\n",
    "# Sorting the data according to the values in the TEAM column.\n",
    "x_test = x_test.sort_values(\"TEAM\")\n",
    "# Resetting the index of the data.\n",
    "x_test = x_test.reset_index()\n",
    "# Dropping the extra index column in the data.\n",
    "x_test = x_test.drop(\"index\", axis=1)\n",
    "x_test = x_test.drop(\"MATCHUP\", axis=1)\n",
    "x_test = x_test.drop(\"WLPCT\", axis=1)\n",
    "# Assigning the test data to a variable that tells us that this is the prediction that should be made.\n",
    "x_test_prediction = x_test\n",
    "# Dropping the TEAM column in the data.\n",
    "x_test = x_test.drop(\"TEAM\", axis=1)\n",
    "# Assembling in the name of the file that contains the y data that needs to be tested against.\n",
    "y_test = pd.read_csv(\"playoff_labels/east2021playoff.csv\", index_col=0)\n",
    "# Sorting the data according to the values in the TEAM column.\n",
    "y_test = y_test.sort_values(\"TEAM\")\n",
    "# Resetting the index of the data.\n",
    "y_test = y_test.reset_index()\n",
    "# Dropping the extra index column in the data.\n",
    "y_test = y_test.drop(\"index\", axis=1)\n",
    "# Assigning the test data to a variable that tells us that this is the prediction that should be made.\n",
    "y_test_prediction = y_test\n",
    "# Dropping the TEAM column in the data.\n",
    "y_test = y_test.drop(\"TEAM\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "## STANDARDIZING THE X DATA ##\n",
    "##############################\n",
    "# Creating a scaler object.\n",
    "sc = StandardScaler()\n",
    "# Scaling the x training data.\n",
    "x_train_scaled = sc.fit_transform(x_train)\n",
    "# Scaling the x test data.\n",
    "x_test_scaled = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "## NORMALIZING THE X DATA ##\n",
    "############################\n",
    "# Normalizing the x scaled training data.\n",
    "a = preprocessing.normalize(x_train_scaled, axis = 0)\n",
    "# Creating a new dataframe to hold the saled, normalized x training data.\n",
    "x_train_normalized = pd.DataFrame(a, columns = x_train.columns)\n",
    "# Normalizing the x scaled testing data.\n",
    "b = preprocessing.normalize(x_test_scaled, axis = 0)\n",
    "# Creating a new dataframe to hold the saled, normalized x testing data.\n",
    "x_test_normalized = pd. DataFrame (b, columns = x_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION MODEL FOR THE 2021 NBA SEASON IN THE EASTERN CONFERENCE\n",
      "\n",
      "Score for training data: 0.8066666666666666\n",
      "Score for testing data: 0.6666666666666666\n",
      "\n",
      "Most important features for 2021 in the Eastern Conference\n",
      "('PM', 4.192892339967322, 4.192892339967322)\n",
      "('FGPCT', 1.5612884719530524, 1.5612884719530524)\n",
      "('FG3PCT', 1.2539959951474446, 1.2539959951474446)\n",
      "('TOV', -1.2041265228950269, 1.2041265228950269)\n",
      "('STL', 1.1156588648834882, 1.1156588648834882)\n",
      "\n",
      "Predictions for which teams makes the playoffs for 2021 in the Eastern Conference\n",
      "   TEAM  PLAYOFF  PREDICTION  PROBABILITY\n",
      "9   MIL        1           1     0.992836\n",
      "1   BKN        1           1     0.991893\n",
      "12  PHI        1           1     0.991308\n",
      "0   ATL        1           1     0.941744\n",
      "7   IND        0           1     0.938224\n",
      "13  TOR        0           1     0.921534\n",
      "2   BOS        1           1     0.852492\n",
      "3   CHA        0           1     0.781242\n",
      "10  NYK        1           1     0.754992\n",
      "4   CHI        0           1     0.749082\n",
      "8   MIA        1           1     0.733233\n",
      "6   DET        0           1     0.568021\n",
      "14  WAS        1           1     0.560304\n",
      "11  ORL        0           0     0.225583\n",
      "5   CLE        0           0     0.119726\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "## LOGISTIC REGRESSION MODEL ##\n",
    "###############################\n",
    "\n",
    "print(\"LOGISTIC REGRESSION MODEL FOR THE 2021 NBA SEASON IN THE EASTERN CONFERENCE\")\n",
    "print()\n",
    "# Creating a logistic regression object.\n",
    "east_logreg = LogisticRegression()\n",
    "# Fitting the model with the normalized x training and y training data.\n",
    "east_logreg.fit(x_train_normalized, np.ravel(y_train))\n",
    "# Getting the score from the normalized x training and y trianing data.\n",
    "east_logreg_train_score = east_logreg.score(x_train_normalized, y_train)\n",
    "# Printing out this score.\n",
    "print(\"Score for training data: \" + str(east_logreg_train_score))\n",
    "# Getting the score from the normalized x testing and y testing data.\n",
    "east_logreg_test_score = east_logreg.score(x_test_normalized, y_test)\n",
    "# Printing out this score.\n",
    "print(\"Score for testing data: \" + str(east_logreg_test_score))\n",
    "print()\n",
    "# Getting the names of the columns in the x training dataset.\n",
    "train_feature_names = x_train.columns\n",
    "print(\"Most important features for 2021 in the Eastern Conference\")\n",
    "# Calculating the coeffeicnt for the logistic regression model. \n",
    "coefficient_logreg = east_logreg.coef_\n",
    "# Getting the most important coefficient value which would be the first one in the list.\n",
    "importance_logreg = coefficient_logreg[0]\n",
    "# Taking the absolute value of this coeffficient.\n",
    "abs_importance_logreg = abs(importance_logreg)\n",
    "# Making a list of the feature names, the importance coeffeicient and the absolute value of this coefficient.\n",
    "importance_list_log = list(zip(train_feature_names, importance_logreg, abs_importance_logreg))\n",
    "# Sorting this list according to the absolute values of the coefficient.\n",
    "importance_list_log.sort(key=lambda x: x[2], reverse=True)\n",
    "for i in range(5):\n",
    "    print(importance_list_log[i])\n",
    "print()\n",
    "print(\"Predictions for which teams makes the playoffs for 2021 in the Eastern Conference\")\n",
    "# Getting the teams and whether they made it to the playoffs in our testing data. This will be the prediction that we would like to match.\n",
    "east_predictions_2021_LR = y_test_prediction[[\"TEAM\", \"PLAYOFF\"]]\n",
    "# Getting the probability of this predction, using the x data.\n",
    "logreg_probability = east_logreg.predict_proba(x_test_normalized)[:, 1].tolist()\n",
    "# Making a new predcition.\n",
    "logreg_prediction = east_logreg.predict(x_test_normalized).tolist()\n",
    "# Assigning the prediction value to the prediciotn column in the list.\n",
    "east_predictions_2021_LR[\"PREDICTION\"] = logreg_prediction\n",
    "# Assigning the probabilities to the column in the list.\n",
    "east_predictions_2021_LR[\"PROBABILITY\"] = logreg_probability\n",
    "# Sorting the list according to the porbability values.\n",
    "east_predictions_2021_LR = east_predictions_2021_LR.sort_values(\"PROBABILITY\", ascending=False)\n",
    "print(east_predictions_2021_LR)\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM MODEL FOR THE 2021 NBA SEASON IN THE EASTERN CONFERENCE\n",
      "\n",
      "Score for training data: 0.83\n",
      "Score for testing data: 0.6666666666666666\n",
      "\n",
      "Most important features for 2021 in the Eastern Conference\n",
      "('PM', 6.619356851213325, 6.619356851213325)\n",
      "('TOV', -2.128579788769111, 2.128579788769111)\n",
      "('STL', 1.8783485152102481, 1.8783485152102481)\n",
      "('FGA', -1.8565698743163028, 1.8565698743163028)\n",
      "('FGPCT', 1.8146080083443126, 1.8146080083443126)\n",
      "\n",
      "Predictions for which teams makes the playoffs for 2021 in the Eastern Conference\n",
      "   TEAM  PLAYOFF  PREDICTION  PROBABILITY\n",
      "1   BKN        1           1     1.000000\n",
      "9   MIL        1           1     1.000000\n",
      "12  PHI        1           1     1.000000\n",
      "7   IND        0           1     1.000000\n",
      "0   ATL        1           1     1.000000\n",
      "13  TOR        0           1     1.000000\n",
      "2   BOS        1           1     0.999997\n",
      "10  NYK        1           1     0.985581\n",
      "3   CHA        0           1     0.982082\n",
      "8   MIA        1           1     0.974570\n",
      "4   CHI        0           1     0.851481\n",
      "6   DET        0           1     0.520420\n",
      "14  WAS        1           0     0.120357\n",
      "11  ORL        0           0     0.000673\n",
      "5   CLE        0           0     0.000010\n"
     ]
    }
   ],
   "source": [
    "###############\n",
    "## SVM MODEL ##\n",
    "###############\n",
    "\n",
    "print(\"SVM MODEL FOR THE 2021 NBA SEASON IN THE EASTERN CONFERENCE\")\n",
    "print()\n",
    "# Making SVM model.\n",
    "east_svm = SVC(kernel=\"linear\", probability=True)\n",
    "# Fitting the data to the model.\n",
    "east_svm.fit(x_train_normalized, np.ravel(y_train))\n",
    "# Calculating the score from the x and y training data.\n",
    "east_svm_train_score = east_svm.score(x_train_normalized, y_train)\n",
    "# Printing the score for the training data.\n",
    "print(\"Score for training data: \" + str(east_svm_train_score))\n",
    "# Printing the score for the test data.\n",
    "east_svm_test_score = east_svm.score(x_test, y_test)\n",
    "# Printing the score for the training data.\n",
    "print(\"Score for testing data: \" + str(east_svm_test_score))\n",
    "print()\n",
    "# Getting the names of the columns in the x training dataset.\n",
    "train_feature_names_SVM = x_train.columns\n",
    "print(\"Most important features for 2021 in the Eastern Conference\")\n",
    "# Calculating the coefficient for the SVM.\n",
    "coefficient_svm = east_svm.coef_\n",
    "# Getting the most important coefficient value which would be the first one in the list.\n",
    "importance_svm = coefficient_svm[0]\n",
    "# Taking the absolute value of this coeffficient.\n",
    "abs_importance_svm = abs(importance_svm)\n",
    "# Making a list of the feature names, the importance coeffeicient and the absolute value of this coefficient.\n",
    "importance_list_svm = list(zip(train_feature_names_SVM, importance_svm, abs_importance_svm))\n",
    "# Sorting this list according to the absolute values of the coefficient.\n",
    "importance_list_svm.sort(key=lambda x: x[2], reverse=True)\n",
    "for i in range(5):\n",
    "    print(importance_list_svm[i])\n",
    "print()\n",
    "print(\"Predictions for which teams makes the playoffs for 2021 in the Eastern Conference\")\n",
    "# Getting the teams and whether they made it to the playoffs in our testing data. This will be the prediction that we would like to match.\n",
    "east_predictions_2021_SVM = y_test_prediction[[\"TEAM\", \"PLAYOFF\"]]\n",
    "# Getting the probability of this predction, using the x data.\n",
    "svm_probability = east_svm.predict_proba(x_test_normalized)[:, 1].tolist()\n",
    "# Making a new predcition.\n",
    "svm_prediction = east_svm.predict(x_test_normalized).tolist()\n",
    "# Assigning the prediction value to the prediciotn colum in the list.\n",
    "east_predictions_2021_SVM[\"PREDICTION\"] = svm_prediction\n",
    "# Assigning the probabilities to the column in the list.\n",
    "east_predictions_2021_SVM[\"PROBABILITY\"] = svm_probability\n",
    "# Sorting the list according to the porbability values.\n",
    "east_predictions_2021_SVM = east_predictions_2021_SVM.sort_values(\"PROBABILITY\", ascending=False)\n",
    "print(east_predictions_2021_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s6/zwdczv3908n6dhrky_00nygh0000gn/T/ipykernel_68061/1780786906.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  east_rf.fit(x_train_normalized, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for training data: 1.0\n",
      "Score for testing data: 0.8666666666666667\n",
      "\n",
      "(0.28113220848728004, 'PM')\n",
      "(0.26952570629571193, 'WLPCT')\n",
      "(0.056028405311697546, 'FGPCT')\n",
      "(0.038403198793920186, 'STL')\n",
      "(0.03671874850227071, 'AST')\n",
      "\n",
      "Predictions for which teams makes the playoffs for 2021 in the Eastern Conference\n",
      "\n",
      "   TEAM  PLAYOFF  PREDICTION  PROBABILITY\n",
      "5   LAL        1           1         0.81\n",
      "14  UTA        1           1         0.81\n",
      "1   DEN        1           1         0.80\n",
      "4   LAC        1           1         0.79\n",
      "10  PHX        1           1         0.72\n",
      "11  POR        1           1         0.59\n",
      "13  SAS        0           1         0.55\n",
      "0   DAL        1           1         0.54\n",
      "6   MEM        1           0         0.35\n",
      "2   GSW        0           0         0.29\n",
      "8   NOP        0           0         0.29\n",
      "9   OKC        0           0         0.24\n",
      "12  SAC        0           0         0.21\n",
      "3   HOU        0           0         0.20\n",
      "7   MIN        0           0         0.20\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "## Random Forest Classifier Model ##\n",
    "####################################\n",
    "\n",
    "\n",
    "east_rf = RandomForestClassifier()\n",
    "east_rf.fit(x_train_normalized, y_train)\n",
    "# Getting the score from the normalized x training and y trianing data.\n",
    "east_rf_train_score = east_rf.score(x_train_normalized, y_train)\n",
    "# Printing out this score.\n",
    "print(\"Score for training data: \" + str(east_rf_train_score))\n",
    "# Getting the score from the normalized x testing and y testing data.\n",
    "east_rf_test_score = east_rf.score(x_test_normalized, y_test)\n",
    "# Printing out this score.\n",
    "print(\"Score for testing data: \" + str(east_rf_test_score))\n",
    "print()\n",
    "\n",
    "# Getting the names of the columns in the x training dataset.\n",
    "train_feature_names = x_train.columns\n",
    "\n",
    "# Getting the feature importances for all of the features trained in the model\n",
    "rf_importances = east_rf.feature_importances_\n",
    "# Making a list of the feature importances and feature names\n",
    "rf_importances = sorted(zip(rf_importances, train_feature_names), reverse=True)\n",
    "# Sorting this list to find the most important features from the model\n",
    "for i in range(5):\n",
    "    print(rf_importances[i])\n",
    "\n",
    "print()\n",
    "print(\"Predictions for which teams makes the playoffs for 2021 in the Eastern Conference\")\n",
    "print()\n",
    "# Getting the teams and whether they made it to the playoffs in our testing data. This will be the prediction that we would like to match.\n",
    "east_predictions_2021 = y_test_prediction[[\"TEAM\", \"PLAYOFF\"]]\n",
    "# Getting the probability of this predction, using the x data.\n",
    "rf_probability = east_rf.predict_proba(x_test_normalized)[:, 1].tolist()\n",
    "# Making a new predcition.\n",
    "rf_prediction = east_rf.predict(x_test_normalized).tolist()\n",
    "# Assinging the prediciotn value to the prediciotn colum in the list.\n",
    "east_predictions_2021[\"PREDICTION\"] = rf_prediction\n",
    "# Assigning the probabilities to the column in the list..\n",
    "east_predictions_2021[\"PROBABILITY\"] = rf_probability\n",
    "# Sorting the list according to the porbability values.\n",
    "east_predictions_2021 = east_predictions_2021.sort_values(\"PROBABILITY\", ascending=False)\n",
    "print(east_predictions_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 2, 'max_features': 18, 'min_samples_leaf': 10}\n",
      "Accuracy:  87.33333333333333\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "## Decision Tree Classifier Model ##\n",
    "####################################\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=12, max_features=12, min_samples_leaf=20)\n",
    "# Create dictionary of parameters to find the most optimal hyperparameters for the model\n",
    "params = {'max_depth': [2, 4, 6, 8, 10, 12],\n",
    "          'min_samples_leaf': [5, 10, 15, 20, 25, 30],\n",
    "          'max_features': [10, 12, 14, 16, 18, 20]}\n",
    "# Use GridSearchCV to find most optimal hyperparameters\n",
    "grid_search = GridSearchCV(clf, params, cv = 10, scoring = 'accuracy')\n",
    "# Fit the model to calculate the most optimal hyperparameters\n",
    "grid_search.fit(x_train_normalized, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(\"Accuracy: \", grid_search.best_score_ * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.843262164614981, 'PM')\n",
      "(0.043572894011796044, 'FGA')\n",
      "(0.03614740292862713, 'OREB')\n",
      "(0.027842625327809636, 'TOV')\n",
      "(0.025252586827309104, 'STL')\n",
      "\n",
      "Score for training data: 0.91\n",
      "Score for testing data: 0.7333333333333333\n",
      "\n",
      "Predictions for which teams makes the playoffs for 2021 in the Eastern Conference\n",
      "\n",
      "   TEAM  PLAYOFF  PREDICTION  PROBABILITY\n",
      "0   ATL        1           1     1.000000\n",
      "1   BKN        1           1     1.000000\n",
      "2   BOS        1           1     1.000000\n",
      "4   CHI        0           1     1.000000\n",
      "7   IND        0           1     1.000000\n",
      "9   MIL        1           1     1.000000\n",
      "10  NYK        1           1     1.000000\n",
      "12  PHI        1           1     1.000000\n",
      "13  TOR        0           1     1.000000\n",
      "8   MIA        1           1     0.941176\n",
      "3   CHA        0           0     0.100000\n",
      "6   DET        0           0     0.100000\n",
      "11  ORL        0           0     0.100000\n",
      "14  WAS        1           0     0.100000\n",
      "5   CLE        0           0     0.000000\n"
     ]
    }
   ],
   "source": [
    "# Fit the model based on the optimized hyperparameters\n",
    "clf = DecisionTreeClassifier(max_features=18, min_samples_leaf=10)\n",
    "clf.fit(x_train_normalized, y_train)\n",
    "\n",
    "train_feature_names = x_train.columns\n",
    "\n",
    "# Getting the feature importances for all of the features trained in the model\n",
    "dt_importances = clf.feature_importances_\n",
    "# Sorting this list to find the most important features from the model\n",
    "dt_importances = sorted(zip(dt_importances, train_feature_names), reverse=True)\n",
    "# Sorting this list to find the most important features from the model\n",
    "for i in range (5):\n",
    "    print (dt_importances[i])\n",
    "\n",
    "# Getting the score from the normalized x training and y trianing data.\n",
    "east_dt_train_score = clf.score(x_train_normalized, y_train)\n",
    "# east_logreg_train_score = east_logreg.score(x_train_normalized, y_train)\n",
    "# Printing out this score.\n",
    "print()\n",
    "print(\"Score for training data: \" + str(east_dt_train_score))\n",
    "# Getting the score from the normalized x testing and y testing data.\n",
    "east_dt_test_score = clf.score(x_test_normalized, y_test)\n",
    "# Printing out this score.\n",
    "print(\"Score for testing data: \" + str(east_dt_test_score))\n",
    "print()\n",
    "print(\"Predictions for which teams makes the playoffs for 2021 in the Eastern Conference\")\n",
    "print()\n",
    "# Getting the teams and whether they made it to the playoffs in our testing data. This will be the prediction that we would like to match.\n",
    "east_predictions_2021 = y_test_prediction[[\"TEAM\", \"PLAYOFF\"]]\n",
    "# Getting the probability of this predction, using the x data.\n",
    "dt_probability = clf.predict_proba(x_test_normalized)[:, 1].tolist()\n",
    "# rf_probability = rf.predict_proba(x_test_normalized)[:, 1].tolist()\n",
    "# Making a new predcition.\n",
    "dt_prediction = clf.predict(x_test_normalized).tolist()\n",
    "# Assinging the prediciotn value to the prediciotn colum in the list.\n",
    "east_predictions_2021[\"PREDICTION\"] = dt_prediction\n",
    "# Assigning the probabilities to the column in the list..\n",
    "east_predictions_2021[\"PROBABILITY\"] = dt_probability\n",
    "# Sorting the list according to the porbability values.\n",
    "east_predictions_2021 = east_predictions_2021.sort_values(\"PROBABILITY\", ascending=False)\n",
    "print(east_predictions_2021)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "## PREDICTING THE 2021 WESTERN CONFERENCE PLAYOFFS ##\n",
    "######################################################\n",
    "\n",
    "\n",
    "##############################################################\n",
    "## READING IN TRAINING DATA THAT HAS BEEN PREVIOSLY CLEANED ##\n",
    "##############################################################\n",
    "\n",
    "# Creating two empty lists that are used to store the data that is read in.\n",
    "x_train_list = []\n",
    "y_train_list = []\n",
    "# Iterating through the data for all the years.\n",
    "for i in range(2000, 2021):\n",
    "    # We ignore the year of 2004, as there seems to me something wrong with the formatting of the data in out dataset.\n",
    "    if i != 2004:\n",
    "        # Assembling in the name of the file that contains the x data that needs to be trained.\n",
    "        file_name = \"season_stats/west\" + str(i) + \".csv\"\n",
    "        # Reading the x data from the filename created above.\n",
    "        df_x = pd.read_csv(file_name, index_col=0)\n",
    "        # Sorting the data according to the values in the TEAM column.\n",
    "        df_x = df_x.sort_values(\"TEAM\")\n",
    "        # Resetting the index of the data.\n",
    "        df_x = df_x.reset_index()\n",
    "        # Dropping the TEAM column in the data.\n",
    "        df_x = df_x.drop(\"TEAM\", axis=1)\n",
    "        # Dropping the extra index column in the data.\n",
    "        df_x = df_x.drop(\"index\", axis=1)\n",
    "        # Appending the current round of data to the overall list holding all the x data.\n",
    "        x_train_list.append(df_x)\n",
    "        # Assembling in the name of the file that contains the y data that needs to be trained.\n",
    "        file_name = \"playoff_labels/west\" + str(i) + \"playoff.csv\"\n",
    "        # Reading the y data from the filename created above.\n",
    "        df_y = pd.read_csv(file_name, index_col=0)\n",
    "        # Sorting the data according to the values in the TEAM column.\n",
    "        df_y = df_y.sort_values(\"TEAM\")\n",
    "        # Resetting the index of the data.\n",
    "        df_y = df_y.reset_index()\n",
    "        # Dropping the TEAM column in the data.\n",
    "        df_y = df_y.drop(\"TEAM\", axis=1)\n",
    "        # Dropping the extra index column in the data.\n",
    "        df_y = df_y.drop(\"index\", axis=1)\n",
    "        # Appending the current round of data to the overall list holding all the y data.\n",
    "        y_train_list.append(df_y)\n",
    "\n",
    "# Concatentating the list of x data to a dataframe to hold all the x data.\n",
    "x_train = pd.concat(x_train_list)\n",
    "x_train = x_train.drop(\"MATCHUP\", axis=1)\n",
    "# x_train = x_train.drop(\"WLPCT\", axis=1)\n",
    "# Concatentating the list of y data to a dataframe to hold all the y data.\n",
    "y_train = pd.concat(y_train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "## READING IN THE TEST DATA ##\n",
    "##############################\n",
    "\n",
    "# Assembling in the name of the file that contains the x data that needs to be tested against.\n",
    "x_test = pd.read_csv(\"season_stats/west2021.csv\", index_col=0)\n",
    "# Sorting the data according to the values in the TEAM column.\n",
    "x_test = x_test.sort_values(\"TEAM\")\n",
    "# Resetting the index of the data.\n",
    "x_test = x_test.reset_index()\n",
    "# Dropping the extra index column in the data.\n",
    "x_test = x_test.drop(\"index\", axis=1)\n",
    "x_test = x_test.drop(\"MATCHUP\", axis=1)\n",
    "# x_test = x_test.drop(\"WLPCT\", axis=1)\n",
    "# Assigning the test data to a variable that tells us that this is the prediction that should be made.\n",
    "x_test_prediction = x_test\n",
    "# Dropping the TEAM column in the data.\n",
    "x_test = x_test.drop(\"TEAM\", axis=1)\n",
    "# Assembling in the name of the file that contains the y data that needs to be tested against.\n",
    "y_test = pd.read_csv(\"playoff_labels/west2021playoff.csv\", index_col=0)\n",
    "# Sorting the data according to the values in the TEAM column.\n",
    "y_test = y_test.sort_values(\"TEAM\")\n",
    "# Resetting the index of the data.\n",
    "y_test = y_test.reset_index()\n",
    "# Dropping the extra index column in the data.\n",
    "y_test = y_test.drop(\"index\", axis=1)\n",
    "# Assigning the test data to a variable that tells us that this is the prediction that should be made.\n",
    "y_test_prediction = y_test\n",
    "# Dropping the TEAM column in the data.\n",
    "y_test = y_test.drop(\"TEAM\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "## STANDARDIZING THE X DATA ##\n",
    "##############################\n",
    "# Creating a scaler object.\n",
    "sc = StandardScaler()\n",
    "# Scaling the x training data.\n",
    "x_train_scaled = sc.fit_transform(x_train)\n",
    "# Scaling the x test data.\n",
    "x_test_scaled = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "## NORMALIZING THE X DATA ##\n",
    "############################\n",
    "# Normalizing the x scaled training data.\n",
    "a = preprocessing.normalize(x_train_scaled, axis = 0)\n",
    "# Creating a new dataframe to hold the saled, normalized x training data.\n",
    "x_train_normalized = pd.DataFrame(a, columns = x_train.columns)\n",
    "# Normalizing the x scaled testing data.\n",
    "b = preprocessing.normalize(x_test_scaled, axis = 0)\n",
    "# Creating a new dataframe to hold the saled, normalized x testing data.\n",
    "x_test_normalized = pd. DataFrame (b, columns = x_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC REGRESSION MODEL FOR THE 2021 NBA SEASON IN THE WESTERN CONFERENCE\n",
      "\n",
      "Score for training data: 0.8513513513513513\n",
      "Score for testing data: 0.8\n",
      "\n",
      "Most important features for 2021 in the Western Conference\n",
      "('WLPCT', 3.9489615636330027, 3.9489615636330027)\n",
      "('PM', 3.7495904218670852, 3.7495904218670852)\n",
      "('FGPCT', 1.7897564091541547, 1.7897564091541547)\n",
      "('TOV', -1.2066008015955436, 1.2066008015955436)\n",
      "('AST', 1.0476024095510832, 1.0476024095510832)\n",
      "\n",
      "Predictions for which teams makes the playoffs for 2021 in the Western Conference\n",
      "   TEAM  PLAYOFF  PREDICTION  PROBABILITY\n",
      "14  UTA        1           1     0.990260\n",
      "5   LAL        1           1     0.982672\n",
      "10  PHX        1           1     0.982620\n",
      "4   LAC        1           1     0.979016\n",
      "1   DEN        1           1     0.971793\n",
      "6   MEM        1           1     0.791036\n",
      "11  POR        1           1     0.788287\n",
      "13  SAS        0           1     0.757186\n",
      "0   DAL        1           1     0.755370\n",
      "2   GSW        0           1     0.704276\n",
      "8   NOP        0           1     0.659207\n",
      "12  SAC        0           0     0.302502\n",
      "9   OKC        0           0     0.097975\n",
      "7   MIN        0           0     0.033486\n",
      "3   HOU        0           0     0.023062\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "## LOGISTIC REGRESSION MODEL ##\n",
    "###############################\n",
    "\n",
    "print(\"LOGISTIC REGRESSION MODEL FOR THE 2021 NBA SEASON IN THE WESTERN CONFERENCE\")\n",
    "print()\n",
    "# Creating a logistic regression object.\n",
    "west_logreg = LogisticRegression()\n",
    "# Fitting the model with the normalized x training and y training data.\n",
    "west_logreg.fit(x_train_normalized, np.ravel(y_train))\n",
    "# Getting the score from the normalized x training and y trianing data.\n",
    "west_logreg_train_score = west_logreg.score(x_train_normalized, y_train)\n",
    "# Printing out this score.\n",
    "print(\"Score for training data: \" + str(west_logreg_train_score))\n",
    "# Getting the score from the normalized x testing and y testing data.\n",
    "west_logreg_test_score = west_logreg.score(x_test_normalized, y_test)\n",
    "# Printing out this score.\n",
    "print(\"Score for testing data: \" + str(west_logreg_test_score))\n",
    "print()\n",
    "# Getting the names of the columns in the x training dataset.\n",
    "train_feature_names = x_train.columns\n",
    "print(\"Most important features for 2021 in the Western Conference\")\n",
    "# Calculating the coeffeicnt for the logistic regression model.\n",
    "coefficient_logreg = west_logreg.coef_\n",
    "# Getting the most important coefficient value which would be the first one in the list.\n",
    "importance_logreg = coefficient_logreg[0]\n",
    "# Taking the absolute value of this coeffficient.\n",
    "abs_importance_logreg = abs(importance_logreg)\n",
    "# Making a list of the feature names, the importance coeffeicient and the absolute value of this coefficient.\n",
    "importance_list_log = list(zip(train_feature_names, importance_logreg, abs_importance_logreg))\n",
    "# Sorting this list according to the absolute values of the coefficient.\n",
    "importance_list_log.sort(key=lambda x: x[2], reverse=True)\n",
    "for i in range(5):\n",
    "    print(importance_list_log[i])\n",
    "print()\n",
    "print(\"Predictions for which teams makes the playoffs for 2021 in the Western Conference\")\n",
    "# Getting the teams and whether they made it to the playoffs in our testing data. This will be the prediction that we would like to match.\n",
    "west_predictions_2021_LR = y_test_prediction[[\"TEAM\", \"PLAYOFF\"]]\n",
    "# Getting the probability of this predction, using the x data.\n",
    "logreg_probability = west_logreg.predict_proba(x_test_normalized)[:, 1].tolist()\n",
    "# Making a new predcition.\n",
    "logreg_prediction = west_logreg.predict(x_test_normalized).tolist()\n",
    "# Assigning the prediction value to the prediciotn column in the list.\n",
    "west_predictions_2021_LR[\"PREDICTION\"] = logreg_prediction\n",
    "# Assigning the probabilities to the column in the list.\n",
    "west_predictions_2021_LR[\"PROBABILITY\"] = logreg_probability\n",
    "# Sorting the list according to the porbability values.\n",
    "west_predictions_2021_LR = west_predictions_2021_LR.sort_values(\"PROBABILITY\", ascending=False)\n",
    "print(west_predictions_2021_LR)\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM MODEL FOR THE 2021 NBA SEASON IN THE WESTERN CONFERENCE\n",
      "\n",
      "Score for training data: 0.8513513513513513\n",
      "Score for testing data: 0.8666666666666667\n",
      "\n",
      "Most important features for 2021 in the Western Conference\n",
      "('WLPCT', 5.789988836508184, 5.789988836508184)\n",
      "('PM', 5.168403969489876, 5.168403969489876)\n",
      "('FGPCT', 2.228850098482319, 2.228850098482319)\n",
      "('TOV', -1.642327804536691, 1.642327804536691)\n",
      "('STL', 1.5457691263662912, 1.5457691263662912)\n",
      "\n",
      "Predictions for which teams makes the playoffs for 2021 in the Western Conference\n",
      "   TEAM  PLAYOFF  PREDICTION   PROBABILITY\n",
      "5   LAL        1           1  1.000000e+00\n",
      "10  PHX        1           1  1.000000e+00\n",
      "14  UTA        1           1  1.000000e+00\n",
      "4   LAC        1           1  1.000000e+00\n",
      "1   DEN        1           1  1.000000e+00\n",
      "6   MEM        1           1  9.967939e-01\n",
      "13  SAS        0           1  9.608534e-01\n",
      "0   DAL        1           1  9.563962e-01\n",
      "11  POR        1           1  9.486330e-01\n",
      "2   GSW        0           1  8.761792e-01\n",
      "8   NOP        0           1  7.354512e-01\n",
      "12  SAC        0           0  9.215642e-04\n",
      "9   OKC        0           0  3.406146e-06\n",
      "3   HOU        0           0  1.000000e-07\n",
      "7   MIN        0           0  1.000000e-07\n"
     ]
    }
   ],
   "source": [
    "###############\n",
    "## SVM MODEL ##\n",
    "###############\n",
    "\n",
    "print(\"SVM MODEL FOR THE 2021 NBA SEASON IN THE WESTERN CONFERENCE\")\n",
    "print()\n",
    "# Making SVM model.\n",
    "west_svm = SVC(kernel=\"linear\", probability=True)\n",
    "# Fitting the data to the model.\n",
    "west_svm.fit(x_train_normalized, np.ravel(y_train))\n",
    "# Calculating the score from the x and y training data.\n",
    "west_svm_train_score = west_svm.score(x_train_normalized, y_train)\n",
    "# Printing the score for the training data.\n",
    "print(\"Score for training data: \" + str(west_svm_train_score))\n",
    "# Printing the score for the test data.\n",
    "west_svm_test_score = west_svm.score(x_test, y_test)\n",
    "# Printing the score for the training data.\n",
    "print(\"Score for testing data: \" + str(west_svm_test_score))\n",
    "print()\n",
    "# Getting the names of the columns in the x training dataset.\n",
    "train_feature_names_SVM = x_train.columns\n",
    "print(\"Most important features for 2021 in the Western Conference\")\n",
    "# Calculating the coefficient for the SVM.\n",
    "coefficient_svm = west_svm.coef_\n",
    "# Getting the most important coefficient value which would be the first one in the list.\n",
    "importance_svm = coefficient_svm[0]\n",
    "# Taking the absolute value of this coeffficient.\n",
    "abs_importance_svm = abs(importance_svm)\n",
    "# Making a list of the feature names, the importance coeffeicient and the absolute value of this coefficient.\n",
    "importance_list_svm = list(zip(train_feature_names_SVM, importance_svm, abs_importance_svm))\n",
    "# Sorting this list according to the absolute values of the coefficient.\n",
    "importance_list_svm.sort(key=lambda x: x[2], reverse=True)\n",
    "for i in range(5):\n",
    "    print(importance_list_svm[i])\n",
    "print()\n",
    "print(\"Predictions for which teams makes the playoffs for 2021 in the Western Conference\")\n",
    "# Getting the teams and whether they made it to the playoffs in our testing data. This will be the prediction that we would like to match.\n",
    "west_predictions_2021_SVM = y_test_prediction[[\"TEAM\", \"PLAYOFF\"]]\n",
    "# Getting the probability of this predction, using the x data.\n",
    "svm_probability = west_svm.predict_proba(x_test_normalized)[:, 1].tolist()\n",
    "# Making a new predcition.\n",
    "svm_prediction = west_svm.predict(x_test_normalized).tolist()\n",
    "# Assigning the prediction value to the prediction column in the list.\n",
    "west_predictions_2021_SVM[\"PREDICTION\"] = svm_prediction\n",
    "# Assigning the probabilities to the column in the list.\n",
    "west_predictions_2021_SVM[\"PROBABILITY\"] = svm_probability\n",
    "# Sorting the list according to the probability values.\n",
    "west_predictions_2021_SVM = west_predictions_2021_SVM.sort_values(\"PROBABILITY\", ascending=False)\n",
    "print(west_predictions_2021_SVM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s6/zwdczv3908n6dhrky_00nygh0000gn/T/ipykernel_68061/1952186554.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  west_rf.fit(x_train_normalized, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for training data: 1.0\n",
      "Score for testing data: 0.9333333333333333\n",
      "\n",
      "(0.29405246601767454, 'PM')\n",
      "(0.23066369481345275, 'WLPCT')\n",
      "(0.06086579122961656, 'FGPCT')\n",
      "(0.04020644157837555, 'DREB')\n",
      "(0.0337298526613665, 'STL')\n",
      "\n",
      "Predictions for which teams makes the playoffs for 2021 in the Eastern Conference\n",
      "\n",
      "   TEAM  PLAYOFF  PREDICTION  PROBABILITY\n",
      "5   LAL        1           1         0.76\n",
      "14  UTA        1           1         0.75\n",
      "4   LAC        1           1         0.74\n",
      "1   DEN        1           1         0.72\n",
      "10  PHX        1           1         0.69\n",
      "11  POR        1           1         0.62\n",
      "0   DAL        1           1         0.53\n",
      "13  SAS        0           0         0.48\n",
      "6   MEM        1           0         0.37\n",
      "2   GSW        0           0         0.31\n",
      "3   HOU        0           0         0.23\n",
      "9   OKC        0           0         0.23\n",
      "7   MIN        0           0         0.21\n",
      "8   NOP        0           0         0.21\n",
      "12  SAC        0           0         0.20\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "## Random Forest Classifier Model ##\n",
    "####################################\n",
    "\n",
    "\n",
    "west_rf = RandomForestClassifier()\n",
    "west_rf.fit(x_train_normalized, y_train)\n",
    "# Getting the score from the normalized x training and y trianing data.\n",
    "east_rf_train_score = west_rf.score(x_train_normalized, y_train)\n",
    "# Printing out this score.\n",
    "print(\"Score for training data: \" + str(east_rf_train_score))\n",
    "# Getting the score from the normalized x testing and y testing data.\n",
    "east_rf_test_score = west_rf.score(x_test_normalized, y_test)\n",
    "# Printing out this score.\n",
    "print(\"Score for testing data: \" + str(east_rf_test_score))\n",
    "print()\n",
    "\n",
    "# Getting the names of the columns in the x training dataset.\n",
    "train_feature_names = x_train.columns\n",
    "\n",
    "# Getting the feature importances for all of the features trained in the model\n",
    "rf_importances = west_rf.feature_importances_\n",
    "# Making a list of the feature importances and feature names\n",
    "rf_importances = sorted(zip(rf_importances, train_feature_names), reverse=True)\n",
    "# Sorting this list to find the most important features from the model\n",
    "for i in range(5):\n",
    "    print(rf_importances[i])\n",
    "\n",
    "print()\n",
    "print(\"Predictions for which teams makes the playoffs for 2021 in the Eastern Conference\")\n",
    "print()\n",
    "# Getting the teams and whether they made it to the playoffs in our testing data. This will be the prediction that we would like to match.\n",
    "east_predictions_2021 = y_test_prediction[[\"TEAM\", \"PLAYOFF\"]]\n",
    "# Getting the probability of this predction, using the x data.\n",
    "rf_probability = west_rf.predict_proba(x_test_normalized)[:, 1].tolist()\n",
    "# Making a new predcition.\n",
    "rf_prediction = west_rf.predict(x_test_normalized).tolist()\n",
    "# Assinging the prediciotn value to the prediciotn colum in the list.\n",
    "east_predictions_2021[\"PREDICTION\"] = rf_prediction\n",
    "# Assigning the probabilities to the column in the list..\n",
    "east_predictions_2021[\"PROBABILITY\"] = rf_probability\n",
    "# Sorting the list according to the porbability values.\n",
    "east_predictions_2021 = east_predictions_2021.sort_values(\"PROBABILITY\", ascending=False)\n",
    "print(east_predictions_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 4, 'max_features': 12, 'min_samples_leaf': 20}\n",
      "Accuracy:  89.50574712643679\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "## Decision Tree Classifier Model ##\n",
    "####################################\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=4, max_features=12, min_samples_leaf=20)\n",
    "# Create dictionary of parameters to find the most optimal hyperparameters for the model\n",
    "params = {'max_depth': [2, 4, 6, 8, 10, 12],\n",
    "          'min_samples_leaf': [5, 10, 15, 20, 25, 30],\n",
    "          'max_features': [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]}\n",
    "# Use GridSearchCV to find most optimal hyperparameters\n",
    "grid_search = GridSearchCV(clf, params, cv = 10, scoring = 'accuracy')\n",
    "# Fit the model to calculate the most optimal hyperparameters\n",
    "grid_search.fit(x_train_normalized, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(\"Accuracy: \", grid_search.best_score_ * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8619092241627505, 'PM')\n",
      "(0.11433381529827129, 'WLPCT')\n",
      "(0.01637677923614264, 'FTA')\n",
      "(0.006577166184119371, 'DREB')\n",
      "(0.0008030151187161633, 'AST')\n",
      "\n",
      "Score for training data: 0.8851351351351351\n",
      "Score for testing data: 0.8666666666666667\n",
      "\n",
      "Predictions for which teams makes the playoffs for 2021 in the Eastern Conference\n",
      "\n",
      "   TEAM  PLAYOFF  PREDICTION  PROBABILITY\n",
      "0   DAL        1           1     1.000000\n",
      "1   DEN        1           1     1.000000\n",
      "4   LAC        1           1     1.000000\n",
      "5   LAL        1           1     1.000000\n",
      "10  PHX        1           1     1.000000\n",
      "14  UTA        1           1     1.000000\n",
      "2   GSW        0           0     0.382353\n",
      "6   MEM        1           0     0.382353\n",
      "11  POR        1           0     0.382353\n",
      "13  SAS        0           0     0.382353\n",
      "3   HOU        0           0     0.000000\n",
      "7   MIN        0           0     0.000000\n",
      "8   NOP        0           0     0.000000\n",
      "9   OKC        0           0     0.000000\n",
      "12  SAC        0           0     0.000000\n"
     ]
    }
   ],
   "source": [
    "# Fit the model based on the optimized hyperparameters\n",
    "clf = DecisionTreeClassifier(max_depth=4, max_features=12, min_samples_leaf=20)\n",
    "clf.fit(x_train_normalized, y_train)\n",
    "\n",
    "train_feature_names = x_train.columns\n",
    "\n",
    "# Getting the feature importances for all of the features trained in the model\n",
    "dt_importances = clf.feature_importances_\n",
    "# Sorting this list to find the most important features from the model\n",
    "dt_importances = sorted(zip(dt_importances, train_feature_names), reverse=True)\n",
    "# Sorting this list to find the most important features from the model\n",
    "for i in range (5):\n",
    "    print (dt_importances[i])\n",
    "\n",
    "# Getting the score from the normalized x training and y trianing data.\n",
    "east_dt_train_score = clf.score(x_train_normalized, y_train)\n",
    "# east_logreg_train_score = east_logreg.score(x_train_normalized, y_train)\n",
    "# Printing out this score.\n",
    "print()\n",
    "print(\"Score for training data: \" + str(east_dt_train_score))\n",
    "# Getting the score from the normalized x testing and y testing data.\n",
    "east_dt_test_score = clf.score(x_test_normalized, y_test)\n",
    "# Printing out this score.\n",
    "print(\"Score for testing data: \" + str(east_dt_test_score))\n",
    "print()\n",
    "print(\"Predictions for which teams makes the playoffs for 2021 in the Eastern Conference\")\n",
    "print()\n",
    "# Getting the teams and whether they made it to the playoffs in our testing data. This will be the prediction that we would like to match.\n",
    "west_predictions_2021 = y_test_prediction[[\"TEAM\", \"PLAYOFF\"]]\n",
    "# Getting the probability of this predction, using the x data.\n",
    "dt_probability = clf.predict_proba(x_test_normalized)[:, 1].tolist()\n",
    "# rf_probability = rf.predict_proba(x_test_normalized)[:, 1].tolist()\n",
    "# Making a new predcition.\n",
    "dt_prediction = clf.predict(x_test_normalized).tolist()\n",
    "# Assinging the prediciotn value to the prediciotn colum in the list.\n",
    "west_predictions_2021[\"PREDICTION\"] = dt_prediction\n",
    "# Assigning the probabilities to the column in the list..\n",
    "west_predictions_2021[\"PROBABILITY\"] = dt_probability\n",
    "# Sorting the list according to the porbability values.\n",
    "west_predictions_2021 = west_predictions_2021.sort_values(\"PROBABILITY\", ascending=False)\n",
    "print(west_predictions_2021)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
